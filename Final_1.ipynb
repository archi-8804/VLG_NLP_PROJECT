{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501ad0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Archi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Archi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spacy.lang.en import English\n",
    "import en_core_web_sm\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e62d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of pipeline\n",
    "nlp_1 = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565bb014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x1865dae77c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text into individual sentences(used to break sentences in spacy)\n",
    "nlp_1.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad8e15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London bomb survivors launch campaign for public inquiry\n",
      "\n",
      "Sunday, December 18, 2005\n",
      "\n",
      "Survivors of the London Bombings have urged the British public to write to their MPs, and set up an online petition calling for an independent Public Inquiry into the attacks.\n",
      "\n",
      "52 people were killed and hundreds more injured on July 7th 2005 when four suicide bombers blew themselves up on three separate London Underground trains and a public bus.\n",
      "\n",
      "Earlier this week the British government rejected calls for a Public Inquiry, arguing that such an investigation would be too expensive, take too long, and be a distraction from their efforts to combat terrorism. Instead, the government has offered to put together a \"narrative of events\".\n",
      "\n",
      "But survivors of the attack argue that a fully comprehensive investigation could teach valuable lessons which may help reduce the likelihood of future attacks, and improve the response capabilities of the emergency services.\n",
      "\n",
      "Some survivors, such as Rachel North (a pseudonym), who has been active in organising a support group for her fellow victims, have been angered by the government's alternative proposal of a \"narrative\". Writing on the weblog she started to help her, and others, come to terms with the aftermath of July 7th, Ms North says:\n",
      "\n",
      "\"Even if you don't like the questions, don't like the answers, think you know the answers already, Mr Blair, it is us, not you, who are paying the cost for this... If the cost of answering questions makes you squirm, then too bad... We run the risks on the trains, the buses, the streets each day... How dare you presume you know our questions and how dare you presume that they can be answered by a 'narrative of what happened', as if we are children to be placated with a story. I know what happened, I want to know why.\"\n",
      "\n",
      "Ms North also quotes a number of other survivors:\n",
      "\n",
      "\"We are constantly reminded that this is the worst peace time bombing London has ever seen, for something that bad there should be an inquiry. People died, families lost someone they loved and hundreds are still suffering. You can't put a price on that but apparently the government can.\" - \"Fiona\"\n",
      "\n",
      "\"If nothing else, an enquiry would make sure some of these lessons were learnt in case, God forbid, anything like this happened again. I thought there were plansin place for emergencies such as this. Whilst the emergency services did a fantastic job on the day, I have been stunningly underwhelmed by the support offered to victims since.\" - \"Pauline\"\n",
      "\n",
      "An anonymous survivor, writing on the \"Yorkshire lass\" website, says:\n",
      "\n",
      "\"'When I watched the Al-Qaeda video declaring Jihad against the UK I was haunted by the familiarity of the voice, it was my voice, my accent, my dialect. This is not a man who was recruited and trained in some far off country that I have barely heard of, this was a man who was recruited and trained while he lived 20 minutes from my mother's home where I was born and raised.The words he spoke of are words similar to what I have heard many times from disillusioned young men that I studied for my A Levels with. They are the words of hatred I overheard when I worked as a support worker at my local college. They were words of students who were educated... when someone follows through with the actions of those opinions to the detriment of others, questions need to be asked why preventions were not put in place and this needs to be done by public inquiry for peace of mind.I have been told that I am looking for justice in the wrong place and in some way that is right. However, I want some sort of justice, some manner of peace of mind, some questions answered and resolutions made. I don't want others to have to go through what myself and hundreds of other commuters did on that Summer's day.'\"\n",
      "\n",
      "Relatives of the dead have also been very critical. Quoted on the BBC's website, Saba Mozakka, the daughter of Behnaz Mozakka,who died in the Piccadilly Line explosion, said:\n",
      "\n",
      "\"The families will be campaigning for there to be a full public inquiry... A narrative of events will not satisfy anybody. This is not something we will go away on.\"\n",
      "\n",
      "Marie Fatayi-Williams, whose son Anthony was killed in the attack, told the BBC: \"I ask myself - if there is really nothing to hide then why shy away from a public inquiry? It is the only real way that we can truly get things discussed and see for ourselves what happened and what lessons can be learnt and whether we are better prepared now than on 7 July... I have a son who was killed and is never going to come back. Nobody is going to tell me that [an inquiry] is a waste of police time.\"\n",
      "\n",
      "The survivors' petition has so far gathered over 100 signatures. The British government has given no response as yet.\n"
     ]
    }
   ],
   "source": [
    "#Opening the article\n",
    "file_0 = open(\"M0014.english\", \"r\")\n",
    "text_0 = file_0.read()\n",
    "print(text_0)\n",
    "file_0.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1167e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Article added to the pipeline\n",
    "doc_1 = nlp_1(text_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87ca7b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['London bomb survivors launch campaign for public inquiry\\n\\nSunday, December 18, 2005\\n\\nSurvivors of the London Bombings have urged the British public to write to their MPs, and set up an online petition calling for an independent Public Inquiry into the attacks.', '\\n\\n52 people were killed and hundreds more injured on July 7th 2005 when four suicide bombers blew themselves up on three separate London Underground trains and a public bus.', '\\n\\nEarlier this week the British government rejected calls for a Public Inquiry, arguing that such an investigation would be too expensive, take too long, and be a distraction from their efforts to combat terrorism.', 'Instead, the government has offered to put together a \"narrative of events\".', '\\n\\nBut survivors of the attack argue that a fully comprehensive investigation could teach valuable lessons which may help reduce the likelihood of future attacks, and improve the response capabilities of the emergency services.', '\\n\\nSome survivors, such as Rachel North (a pseudonym), who has been active in organising a support group for her fellow victims, have been angered by the government\\'s alternative proposal of a \"narrative\".', 'Writing on the weblog she started to help her, and others, come to terms with the aftermath of July 7th, Ms North says:\\n\\n\"Even if you don\\'t like the questions, don\\'t like the answers, think you know the answers already, Mr Blair, it is us, not you, who are paying the cost for this... If the cost of answering questions makes you squirm, then too bad... We run the risks on the trains, the buses, the streets each day... How dare you presume you know our questions and how dare you presume that they can be answered by a \\'narrative of what happened\\', as if we are children to be placated with a story.', 'I know what happened, I want to know why.\"', '\\n\\nMs North also quotes a number of other survivors:\\n\\n\"We are constantly reminded that this is the worst peace time bombing London has ever seen, for something that bad there should be an inquiry.', 'People died, families lost someone they loved and hundreds are still suffering.', 'You can\\'t put a price on that but apparently the government can.\" - \"', 'Fiona\"\\n\\n\"If nothing else, an enquiry would make sure some of these lessons were learnt in case, God forbid, anything like this happened again.', 'I thought there were plansin place for emergencies such as this.', 'Whilst the emergency services did a fantastic job on the day, I have been stunningly underwhelmed by the support offered to victims since.\" - \"', 'Pauline\"\\n\\nAn anonymous survivor, writing on the \"Yorkshire lass\" website, says:\\n\\n\"\\'When I watched the Al-Qaeda video declaring Jihad against the UK I was haunted by the familiarity of the voice, it was my voice, my accent, my dialect.', \"This is not a man who was recruited and trained in some far off country that I have barely heard of, this was a man who was recruited and trained while he lived 20 minutes from my mother's home where I was born and raised.\", 'The words he spoke of are words similar to what I have heard many times from disillusioned young men that I studied for my A Levels with.', 'They are the words of hatred I overheard when I worked as a support worker at my local college.', 'They were words of students who were educated... when someone follows through with the actions of those opinions to the detriment of others, questions need to be asked why preventions were not put in place and this needs to be done by public inquiry for peace of mind.', 'I have been told that I am looking for justice in the wrong place and in some way that is right.', 'However, I want some sort of justice, some manner of peace of mind, some questions answered and resolutions made.', 'I don\\'t want others to have to go through what myself and hundreds of other commuters did on that Summer\\'s day.\\'\"', '\\n\\nRelatives of the dead have also been very critical.', 'Quoted on the BBC\\'s website, Saba Mozakka, the daughter of Behnaz Mozakka,who died in the Piccadilly Line explosion, said:\\n\\n\"The families will be campaigning for there to be a full public inquiry... A narrative of events will not satisfy anybody.', 'This is not something we will go away on.\"', '\\n\\nMarie Fatayi-Williams, whose son Anthony was killed in the attack, told the BBC: \"I ask myself - if there is really nothing to hide then why shy away from a public inquiry?', 'It is the only real way that we can truly get things discussed and see for ourselves what happened and what lessons can be learnt and whether we are better prepared now than on 7 July... I have a son who was killed and is never going to come back.', 'Nobody is going to tell me that [an inquiry] is a waste of police time.\"', \"\\n\\nThe survivors' petition has so far gathered over 100 signatures.\", 'The British government has given no response as yet.']\n"
     ]
    }
   ],
   "source": [
    "#sentence tokenization using spacy\n",
    "sents_list = [sent.text for sent in doc_1.sents]\n",
    "print(sents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8167bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word tokenization\n",
    "#token_list = [token.text for token in doc_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "477db408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae583bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "613a36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standford core NLP\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "nlp_corenlp = StanfordCoreNLP(r'C:\\stanford-corenlp-4.5.5\\stanford-corenlp-4.5.5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "679c9397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['London', 'bomb', 'survivors', 'launch', 'campaign', 'for', 'public', 'inquiry', 'Sunday', ',', 'December', '18', ',', '2005', 'Survivors', 'of', 'the', 'London', 'Bombings', 'have', 'urged', 'the', 'British', 'public', 'to', 'write', 'to', 'their', 'MPs', ',', 'and', 'set', 'up', 'an', 'online', 'petition', 'calling', 'for', 'an', 'independent', 'Public', 'Inquiry', 'into', 'the', 'attacks', '.', '52', 'people', 'were', 'killed', 'and', 'hundreds', 'more', 'injured', 'on', 'July', '7th', '2005', 'when', 'four', 'suicide', 'bombers', 'blew', 'themselves', 'up', 'on', 'three', 'separate', 'London', 'Underground', 'trains', 'and', 'a', 'public', 'bus', '.', 'Earlier', 'this', 'week', 'the', 'British', 'government', 'rejected', 'calls', 'for', 'a', 'Public', 'Inquiry', ',', 'arguing', 'that', 'such', 'an', 'investigation', 'would', 'be', 'too', 'expensive', ',', 'take', 'too', 'long', ',', 'and', 'be', 'a', 'distraction', 'from', 'their', 'efforts', 'to', 'combat', 'terrorism', '.', 'Instead', ',', 'the', 'government', 'has', 'offered', 'to', 'put', 'together', 'a', '\"', 'narrative', 'of', 'events', '\"', '.', 'But', 'survivors', 'of', 'the', 'attack', 'argue', 'that', 'a', 'fully', 'comprehensive', 'investigation', 'could', 'teach', 'valuable', 'lessons', 'which', 'may', 'help', 'reduce', 'the', 'likelihood', 'of', 'future', 'attacks', ',', 'and', 'improve', 'the', 'response', 'capabilities', 'of', 'the', 'emergency', 'services', '.', 'Some', 'survivors', ',', 'such', 'as', 'Rachel', 'North', '(', 'a', 'pseudonym', ')', ',', 'who', 'has', 'been', 'active', 'in', 'organising', 'a', 'support', 'group', 'for', 'her', 'fellow', 'victims', ',', 'have', 'been', 'angered', 'by', 'the', 'government', \"'s\", 'alternative', 'proposal', 'of', 'a', '\"', 'narrative', '\"', '.', 'Writing', 'on', 'the', 'weblog', 'she', 'started', 'to', 'help', 'her', ',', 'and', 'others', ',', 'come', 'to', 'terms', 'with', 'the', 'aftermath', 'of', 'July', '7th', ',', 'Ms', 'North', 'says', ':', '\"', 'Even', 'if', 'you', 'do', \"n't\", 'like', 'the', 'questions', ',', 'do', \"n't\", 'like', 'the', 'answers', ',', 'think', 'you', 'know', 'the', 'answers', 'already', ',', 'Mr', 'Blair', ',', 'it', 'is', 'us', ',', 'not', 'you', ',', 'who', 'are', 'paying', 'the', 'cost', 'for', 'this', '...', 'If', 'the', 'cost', 'of', 'answering', 'questions', 'makes', 'you', 'squirm', ',', 'then', 'too', 'bad', '...', 'We', 'run', 'the', 'risks', 'on', 'the', 'trains', ',', 'the', 'buses', ',', 'the', 'streets', 'each', 'day', '...', 'How', 'dare', 'you', 'presume', 'you', 'know', 'our', 'questions', 'and', 'how', 'dare', 'you', 'presume', 'that', 'they', 'can', 'be', 'answered', 'by', 'a', \"'\", 'narrative', 'of', 'what', 'happened', \"'\", ',', 'as', 'if', 'we', 'are', 'children', 'to', 'be', 'placated', 'with', 'a', 'story', '.', 'I', 'know', 'what', 'happened', ',', 'I', 'want', 'to', 'know', 'why', '.', '\"', 'Ms', 'North', 'also', 'quotes', 'a', 'number', 'of', 'other', 'survivors', ':', '\"', 'We', 'are', 'constantly', 'reminded', 'that', 'this', 'is', 'the', 'worst', 'peace', 'time', 'bombing', 'London', 'has', 'ever', 'seen', ',', 'for', 'something', 'that', 'bad', 'there', 'should', 'be', 'an', 'inquiry', '.', 'People', 'died', ',', 'families', 'lost', 'someone', 'they', 'loved', 'and', 'hundreds', 'are', 'still', 'suffering', '.', 'You', 'ca', \"n't\", 'put', 'a', 'price', 'on', 'that', 'but', 'apparently', 'the', 'government', 'can', '.', '\"', '-', '\"', 'Fiona', '\"', '\"', 'If', 'nothing', 'else', ',', 'an', 'enquiry', 'would', 'make', 'sure', 'some', 'of', 'these', 'lessons', 'were', 'learnt', 'in', 'case', ',', 'God', 'forbid', ',', 'anything', 'like', 'this', 'happened', 'again', '.', 'I', 'thought', 'there', 'were', 'plansin', 'place', 'for', 'emergencies', 'such', 'as', 'this', '.', 'Whilst', 'the', 'emergency', 'services', 'did', 'a', 'fantastic', 'job', 'on', 'the', 'day', ',', 'I', 'have', 'been', 'stunningly', 'underwhelmed', 'by', 'the', 'support', 'offered', 'to', 'victims', 'since', '.', '\"', '-', '\"', 'Pauline', '\"', 'An', 'anonymous', 'survivor', ',', 'writing', 'on', 'the', '\"', 'Yorkshire', 'lass', '\"', 'website', ',', 'says', ':', '\"', \"'\", 'When', 'I', 'watched', 'the', 'Al', '-', 'Qaeda', 'video', 'declaring', 'Jihad', 'against', 'the', 'UK', 'I', 'was', 'haunted', 'by', 'the', 'familiarity', 'of', 'the', 'voice', ',', 'it', 'was', 'my', 'voice', ',', 'my', 'accent', ',', 'my', 'dialect', '.', 'This', 'is', 'not', 'a', 'man', 'who', 'was', 'recruited', 'and', 'trained', 'in', 'some', 'far', 'off', 'country', 'that', 'I', 'have', 'barely', 'heard', 'of', ',', 'this', 'was', 'a', 'man', 'who', 'was', 'recruited', 'and', 'trained', 'while', 'he', 'lived', '20', 'minutes', 'from', 'my', 'mother', \"'s\", 'home', 'where', 'I', 'was', 'born', 'and', 'raised.The', 'words', 'he', 'spoke', 'of', 'are', 'words', 'similar', 'to', 'what', 'I', 'have', 'heard', 'many', 'times', 'from', 'disillusioned', 'young', 'men', 'that', 'I', 'studied', 'for', 'my', 'A', 'Levels', 'with', '.', 'They', 'are', 'the', 'words', 'of', 'hatred', 'I', 'overheard', 'when', 'I', 'worked', 'as', 'a', 'support', 'worker', 'at', 'my', 'local', 'college', '.', 'They', 'were', 'words', 'of', 'students', 'who', 'were', 'educated', '...', 'when', 'someone', 'follows', 'through', 'with', 'the', 'actions', 'of', 'those', 'opinions', 'to', 'the', 'detriment', 'of', 'others', ',', 'questions', 'need', 'to', 'be', 'asked', 'why', 'preventions', 'were', 'not', 'put', 'in', 'place', 'and', 'this', 'needs', 'to', 'be', 'done', 'by', 'public', 'inquiry', 'for', 'peace', 'of', 'mind.I', 'have', 'been', 'told', 'that', 'I', 'am', 'looking', 'for', 'justice', 'in', 'the', 'wrong', 'place', 'and', 'in', 'some', 'way', 'that', 'is', 'right', '.', 'However', ',', 'I', 'want', 'some', 'sort', 'of', 'justice', ',', 'some', 'manner', 'of', 'peace', 'of', 'mind', ',', 'some', 'questions', 'answered', 'and', 'resolutions', 'made', '.', 'I', 'do', \"n't\", 'want', 'others', 'to', 'have', 'to', 'go', 'through', 'what', 'myself', 'and', 'hundreds', 'of', 'other', 'commuters', 'did', 'on', 'that', 'Summer', \"'s\", 'day', '.', \"'\", '\"', 'Relatives', 'of', 'the', 'dead', 'have', 'also', 'been', 'very', 'critical', '.', 'Quoted', 'on', 'the', 'BBC', \"'s\", 'website', ',', 'Saba', 'Mozakka', ',', 'the', 'daughter', 'of', 'Behnaz', 'Mozakka', ',', 'who', 'died', 'in', 'the', 'Piccadilly', 'Line', 'explosion', ',', 'said', ':', '\"', 'The', 'families', 'will', 'be', 'campaigning', 'for', 'there', 'to', 'be', 'a', 'full', 'public', 'inquiry', '...', 'A', 'narrative', 'of', 'events', 'will', 'not', 'satisfy', 'anybody', '.', 'This', 'is', 'not', 'something', 'we', 'will', 'go', 'away', 'on', '.', '\"', 'Marie', 'Fatayi', '-', 'Williams', ',', 'whose', 'son', 'Anthony', 'was', 'killed', 'in', 'the', 'attack', ',', 'told', 'the', 'BBC', ':', '\"', 'I', 'ask', 'myself', '-', 'if', 'there', 'is', 'really', 'nothing', 'to', 'hide', 'then', 'why', 'shy', 'away', 'from', 'a', 'public', 'inquiry', '?', 'It', 'is', 'the', 'only', 'real', 'way', 'that', 'we', 'can', 'truly', 'get', 'things', 'discussed', 'and', 'see', 'for', 'ourselves', 'what', 'happened', 'and', 'what', 'lessons', 'can', 'be', 'learnt', 'and', 'whether', 'we', 'are', 'better', 'prepared', 'now', 'than', 'on', '7', 'July', '...', 'I', 'have', 'a', 'son', 'who', 'was', 'killed', 'and', 'is', 'never', 'going', 'to', 'come', 'back', '.', 'Nobody', 'is', 'going', 'to', 'tell', 'me', 'that', '[', 'an', 'inquiry', ']', 'is', 'a', 'waste', 'of', 'police', 'time', '.', '\"', 'The', 'survivors', \"'\", 'petition', 'has', 'so', 'far', 'gathered', 'over', '100', 'signatures', '.', 'The', 'British', 'government', 'has', 'given', 'no', 'response', 'as', 'yet', '.']\n"
     ]
    }
   ],
   "source": [
    "# Word tokenization using standford core nlp\n",
    "tokenized_text = nlp_corenlp.word_tokenize(text_0)\n",
    "print( tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a12b4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of Speech: [('London', 'NNP'), ('bomb', 'NN'), ('survivors', 'NNS'), ('launch', 'VBP'), ('campaign', 'NN'), ('for', 'IN'), ('public', 'JJ'), ('inquiry', 'NN'), ('Sunday', 'NNP'), (',', ','), ('December', 'NNP'), ('18', 'CD'), (',', ','), ('2005', 'CD'), ('Survivors', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('London', 'NNP'), ('Bombings', 'NNPS'), ('have', 'VBP'), ('urged', 'VBN'), ('the', 'DT'), ('British', 'JJ'), ('public', 'NN'), ('to', 'TO'), ('write', 'VB'), ('to', 'IN'), ('their', 'PRP$'), ('MPs', 'NNS'), (',', ','), ('and', 'CC'), ('set', 'VBN'), ('up', 'RP'), ('an', 'DT'), ('online', 'JJ'), ('petition', 'NN'), ('calling', 'VBG'), ('for', 'IN'), ('an', 'DT'), ('independent', 'JJ'), ('Public', 'NNP'), ('Inquiry', 'NNP'), ('into', 'IN'), ('the', 'DT'), ('attacks', 'NNS'), ('.', '.'), ('52', 'CD'), ('people', 'NNS'), ('were', 'VBD'), ('killed', 'VBN'), ('and', 'CC'), ('hundreds', 'NNS'), ('more', 'RBR'), ('injured', 'VBN'), ('on', 'IN'), ('July', 'NNP'), ('7th', 'NNP'), ('2005', 'CD'), ('when', 'WRB'), ('four', 'CD'), ('suicide', 'NN'), ('bombers', 'NNS'), ('blew', 'VBD'), ('themselves', 'PRP'), ('up', 'RP'), ('on', 'IN'), ('three', 'CD'), ('separate', 'JJ'), ('London', 'NNP'), ('Underground', 'NNP'), ('trains', 'NNS'), ('and', 'CC'), ('a', 'DT'), ('public', 'JJ'), ('bus', 'NN'), ('.', '.'), ('Earlier', 'RBR'), ('this', 'DT'), ('week', 'NN'), ('the', 'DT'), ('British', 'JJ'), ('government', 'NN'), ('rejected', 'VBD'), ('calls', 'NNS'), ('for', 'IN'), ('a', 'DT'), ('Public', 'NNP'), ('Inquiry', 'NNP'), (',', ','), ('arguing', 'VBG'), ('that', 'IN'), ('such', 'PDT'), ('an', 'DT'), ('investigation', 'NN'), ('would', 'MD'), ('be', 'VB'), ('too', 'RB'), ('expensive', 'JJ'), (',', ','), ('take', 'VB'), ('too', 'RB'), ('long', 'RB'), (',', ','), ('and', 'CC'), ('be', 'VB'), ('a', 'DT'), ('distraction', 'NN'), ('from', 'IN'), ('their', 'PRP$'), ('efforts', 'NNS'), ('to', 'TO'), ('combat', 'VB'), ('terrorism', 'NN'), ('.', '.'), ('Instead', 'RB'), (',', ','), ('the', 'DT'), ('government', 'NN'), ('has', 'VBZ'), ('offered', 'VBN'), ('to', 'TO'), ('put', 'VB'), ('together', 'RB'), ('a', 'DT'), ('\"', '``'), ('narrative', 'NN'), ('of', 'IN'), ('events', 'NNS'), ('\"', \"''\"), ('.', '.'), ('But', 'CC'), ('survivors', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('attack', 'NN'), ('argue', 'VBP'), ('that', 'IN'), ('a', 'DT'), ('fully', 'RB'), ('comprehensive', 'JJ'), ('investigation', 'NN'), ('could', 'MD'), ('teach', 'VB'), ('valuable', 'JJ'), ('lessons', 'NNS'), ('which', 'WDT'), ('may', 'MD'), ('help', 'VB'), ('reduce', 'VB'), ('the', 'DT'), ('likelihood', 'NN'), ('of', 'IN'), ('future', 'JJ'), ('attacks', 'NNS'), (',', ','), ('and', 'CC'), ('improve', 'VB'), ('the', 'DT'), ('response', 'NN'), ('capabilities', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('emergency', 'NN'), ('services', 'NNS'), ('.', '.'), ('Some', 'DT'), ('survivors', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('Rachel', 'NNP'), ('North', 'NNP'), ('(', '-LRB-'), ('a', 'DT'), ('pseudonym', 'NN'), (')', '-RRB-'), (',', ','), ('who', 'WP'), ('has', 'VBZ'), ('been', 'VBN'), ('active', 'JJ'), ('in', 'IN'), ('organising', 'VBG'), ('a', 'DT'), ('support', 'NN'), ('group', 'NN'), ('for', 'IN'), ('her', 'PRP$'), ('fellow', 'JJ'), ('victims', 'NNS'), (',', ','), ('have', 'VBP'), ('been', 'VBN'), ('angered', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('government', 'NN'), (\"'s\", 'POS'), ('alternative', 'JJ'), ('proposal', 'NN'), ('of', 'IN'), ('a', 'DT'), ('\"', '``'), ('narrative', 'NN'), ('\"', \"''\"), ('.', '.'), ('Writing', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('weblog', 'NN'), ('she', 'PRP'), ('started', 'VBD'), ('to', 'TO'), ('help', 'VB'), ('her', 'PRP'), (',', ','), ('and', 'CC'), ('others', 'NNS'), (',', ','), ('come', 'VB'), ('to', 'IN'), ('terms', 'NNS'), ('with', 'IN'), ('the', 'DT'), ('aftermath', 'NN'), ('of', 'IN'), ('July', 'NNP'), ('7th', 'NN'), (',', ','), ('Ms', 'NNP'), ('North', 'NNP'), ('says', 'VBZ'), (':', ':'), ('\"', '``'), ('Even', 'RB'), ('if', 'IN'), ('you', 'PRP'), ('do', 'VBP'), (\"n't\", 'RB'), ('like', 'VB'), ('the', 'DT'), ('questions', 'NNS'), (',', ','), ('do', 'VBP'), (\"n't\", 'RB'), ('like', 'VB'), ('the', 'DT'), ('answers', 'NNS'), (',', ','), ('think', 'VBP'), ('you', 'PRP'), ('know', 'VB'), ('the', 'DT'), ('answers', 'NNS'), ('already', 'RB'), (',', ','), ('Mr', 'NNP'), ('Blair', 'NNP'), (',', ','), ('it', 'PRP'), ('is', 'VBZ'), ('us', 'PRP'), (',', ','), ('not', 'RB'), ('you', 'PRP'), (',', ','), ('who', 'WP'), ('are', 'VBP'), ('paying', 'VBG'), ('the', 'DT'), ('cost', 'NN'), ('for', 'IN'), ('this', 'DT'), ('...', 'NFP'), ('If', 'IN'), ('the', 'DT'), ('cost', 'NN'), ('of', 'IN'), ('answering', 'VBG'), ('questions', 'NNS'), ('makes', 'VBZ'), ('you', 'PRP'), ('squirm', 'VB'), (',', ','), ('then', 'RB'), ('too', 'RB'), ('bad', 'JJ'), ('...', ','), ('We', 'PRP'), ('run', 'VBP'), ('the', 'DT'), ('risks', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('trains', 'NNS'), (',', ','), ('the', 'DT'), ('buses', 'NNS'), (',', ','), ('the', 'DT'), ('streets', 'NNS'), ('each', 'DT'), ('day', 'NN'), ('...', ','), ('How', 'WRB'), ('dare', 'VBP'), ('you', 'PRP'), ('presume', 'VB'), ('you', 'PRP'), ('know', 'VB'), ('our', 'PRP$'), ('questions', 'NNS'), ('and', 'CC'), ('how', 'WRB'), ('dare', 'VBP'), ('you', 'PRP'), ('presume', 'VB'), ('that', 'IN'), ('they', 'PRP'), ('can', 'MD'), ('be', 'VB'), ('answered', 'VBN'), ('by', 'IN'), ('a', 'DT'), (\"'\", '``'), ('narrative', 'NN'), ('of', 'IN'), ('what', 'WP'), ('happened', 'VBD'), (\"'\", \"''\"), (',', ','), ('as', 'IN'), ('if', 'IN'), ('we', 'PRP'), ('are', 'VBP'), ('children', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('placated', 'VBN'), ('with', 'IN'), ('a', 'DT'), ('story', 'NN'), ('.', '.'), ('I', 'PRP'), ('know', 'VBP'), ('what', 'WP'), ('happened', 'VBD'), (',', ','), ('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('know', 'VB'), ('why', 'WRB'), ('.', '.'), ('\"', '``'), ('Ms', 'NNP'), ('North', 'NNP'), ('also', 'RB'), ('quotes', 'VBZ'), ('a', 'DT'), ('number', 'NN'), ('of', 'IN'), ('other', 'JJ'), ('survivors', 'NNS'), (':', ':'), ('\"', '``'), ('We', 'PRP'), ('are', 'VBP'), ('constantly', 'RB'), ('reminded', 'VBN'), ('that', 'IN'), ('this', 'DT'), ('is', 'VBZ'), ('the', 'DT'), ('worst', 'JJS'), ('peace', 'NN'), ('time', 'NN'), ('bombing', 'NN'), ('London', 'NNP'), ('has', 'VBZ'), ('ever', 'RB'), ('seen', 'VBN'), (',', ','), ('for', 'IN'), ('something', 'NN'), ('that', 'WDT'), ('bad', 'JJ'), ('there', 'RB'), ('should', 'MD'), ('be', 'VB'), ('an', 'DT'), ('inquiry', 'NN'), ('.', '.'), ('People', 'NNS'), ('died', 'VBD'), (',', ','), ('families', 'NNS'), ('lost', 'VBD'), ('someone', 'NN'), ('they', 'PRP'), ('loved', 'VBD'), ('and', 'CC'), ('hundreds', 'NNS'), ('are', 'VBP'), ('still', 'RB'), ('suffering', 'VBG'), ('.', '.'), ('You', 'PRP'), ('ca', 'MD'), (\"n't\", 'RB'), ('put', 'VB'), ('a', 'DT'), ('price', 'NN'), ('on', 'IN'), ('that', 'DT'), ('but', 'CC'), ('apparently', 'RB'), ('the', 'DT'), ('government', 'NN'), ('can', 'MD'), ('.', '.'), ('\"', '``'), ('-', ','), ('\"', '``'), ('Fiona', 'NNP'), ('\"', \"''\"), ('\"', '``'), ('If', 'IN'), ('nothing', 'NN'), ('else', 'RB'), (',', ','), ('an', 'DT'), ('enquiry', 'NN'), ('would', 'MD'), ('make', 'VB'), ('sure', 'JJ'), ('some', 'DT'), ('of', 'IN'), ('these', 'DT'), ('lessons', 'NNS'), ('were', 'VBD'), ('learnt', 'VBN'), ('in', 'IN'), ('case', 'NN'), (',', ','), ('God', 'NNP'), ('forbid', 'VB'), (',', ','), ('anything', 'NN'), ('like', 'IN'), ('this', 'DT'), ('happened', 'VBD'), ('again', 'RB'), ('.', '.'), ('I', 'PRP'), ('thought', 'VBD'), ('there', 'EX'), ('were', 'VBD'), ('plansin', 'NN'), ('place', 'NN'), ('for', 'IN'), ('emergencies', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('this', 'DT'), ('.', '.'), ('Whilst', 'IN'), ('the', 'DT'), ('emergency', 'NN'), ('services', 'NNS'), ('did', 'VBD'), ('a', 'DT'), ('fantastic', 'JJ'), ('job', 'NN'), ('on', 'IN'), ('the', 'DT'), ('day', 'NN'), (',', ','), ('I', 'PRP'), ('have', 'VBP'), ('been', 'VBN'), ('stunningly', 'RB'), ('underwhelmed', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('support', 'NN'), ('offered', 'VBD'), ('to', 'IN'), ('victims', 'NNS'), ('since', 'IN'), ('.', '.'), ('\"', '``'), ('-', ','), ('\"', '``'), ('Pauline', 'NNP'), ('\"', \"''\"), ('An', 'DT'), ('anonymous', 'JJ'), ('survivor', 'NN'), (',', ','), ('writing', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('\"', '``'), ('Yorkshire', 'NNP'), ('lass', 'NN'), ('\"', \"''\"), ('website', 'NN'), (',', ','), ('says', 'VBZ'), (':', ':'), ('\"', '``'), (\"'\", '``'), ('When', 'WRB'), ('I', 'PRP'), ('watched', 'VBD'), ('the', 'DT'), ('Al', 'NNP'), ('-', 'HYPH'), ('Qaeda', 'NNP'), ('video', 'NN'), ('declaring', 'VBG'), ('Jihad', 'NN'), ('against', 'IN'), ('the', 'DT'), ('UK', 'NNP'), ('I', 'PRP'), ('was', 'VBD'), ('haunted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('familiarity', 'NN'), ('of', 'IN'), ('the', 'DT'), ('voice', 'NN'), (',', ','), ('it', 'PRP'), ('was', 'VBD'), ('my', 'PRP$'), ('voice', 'NN'), (',', ','), ('my', 'PRP$'), ('accent', 'NN'), (',', ','), ('my', 'PRP$'), ('dialect', 'NN'), ('.', '.'), ('This', 'DT'), ('is', 'VBZ'), ('not', 'RB'), ('a', 'DT'), ('man', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('recruited', 'VBN'), ('and', 'CC'), ('trained', 'VBN'), ('in', 'IN'), ('some', 'DT'), ('far', 'RB'), ('off', 'RB'), ('country', 'NN'), ('that', 'WDT'), ('I', 'PRP'), ('have', 'VBP'), ('barely', 'RB'), ('heard', 'VBN'), ('of', 'IN'), (',', ','), ('this', 'DT'), ('was', 'VBD'), ('a', 'DT'), ('man', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('recruited', 'VBN'), ('and', 'CC'), ('trained', 'VBN'), ('while', 'IN'), ('he', 'PRP'), ('lived', 'VBD'), ('20', 'CD'), ('minutes', 'NNS'), ('from', 'IN'), ('my', 'PRP$'), ('mother', 'NN'), (\"'s\", 'POS'), ('home', 'NN'), ('where', 'WRB'), ('I', 'PRP'), ('was', 'VBD'), ('born', 'VBN'), ('and', 'CC'), ('raised.The', 'NN'), ('words', 'NNS'), ('he', 'PRP'), ('spoke', 'VBD'), ('of', 'IN'), ('are', 'VBP'), ('words', 'NNS'), ('similar', 'JJ'), ('to', 'IN'), ('what', 'WP'), ('I', 'PRP'), ('have', 'VBP'), ('heard', 'VBN'), ('many', 'JJ'), ('times', 'NNS'), ('from', 'IN'), ('disillusioned', 'JJ'), ('young', 'JJ'), ('men', 'NNS'), ('that', 'WDT'), ('I', 'PRP'), ('studied', 'VBD'), ('for', 'IN'), ('my', 'PRP$'), ('A', 'NN'), ('Levels', 'NNS'), ('with', 'IN'), ('.', '.'), ('They', 'PRP'), ('are', 'VBP'), ('the', 'DT'), ('words', 'NNS'), ('of', 'IN'), ('hatred', 'NN'), ('I', 'PRP'), ('overheard', 'VBD'), ('when', 'WRB'), ('I', 'PRP'), ('worked', 'VBD'), ('as', 'IN'), ('a', 'DT'), ('support', 'NN'), ('worker', 'NN'), ('at', 'IN'), ('my', 'PRP$'), ('local', 'JJ'), ('college', 'NN'), ('.', '.'), ('They', 'PRP'), ('were', 'VBD'), ('words', 'NNS'), ('of', 'IN'), ('students', 'NNS'), ('who', 'WP'), ('were', 'VBD'), ('educated', 'VBN'), ('...', ':'), ('when', 'WRB'), ('someone', 'NN'), ('follows', 'VBZ'), ('through', 'IN'), ('with', 'IN'), ('the', 'DT'), ('actions', 'NNS'), ('of', 'IN'), ('those', 'DT'), ('opinions', 'NNS'), ('to', 'IN'), ('the', 'DT'), ('detriment', 'NN'), ('of', 'IN'), ('others', 'NNS'), (',', ','), ('questions', 'NNS'), ('need', 'VBP'), ('to', 'TO'), ('be', 'VB'), ('asked', 'VBN'), ('why', 'WRB'), ('preventions', 'NNS'), ('were', 'VBD'), ('not', 'RB'), ('put', 'VBN'), ('in', 'IN'), ('place', 'NN'), ('and', 'CC'), ('this', 'DT'), ('needs', 'VBZ'), ('to', 'TO'), ('be', 'VB'), ('done', 'VBN'), ('by', 'IN'), ('public', 'JJ'), ('inquiry', 'NN'), ('for', 'IN'), ('peace', 'NN'), ('of', 'IN'), ('mind.I', 'NN'), ('have', 'VBP'), ('been', 'VBN'), ('told', 'VBN'), ('that', 'IN'), ('I', 'PRP'), ('am', 'VBP'), ('looking', 'VBG'), ('for', 'IN'), ('justice', 'NN'), ('in', 'IN'), ('the', 'DT'), ('wrong', 'JJ'), ('place', 'NN'), ('and', 'CC'), ('in', 'IN'), ('some', 'DT'), ('way', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('right', 'JJ'), ('.', '.'), ('However', 'RB'), (',', ','), ('I', 'PRP'), ('want', 'VBP'), ('some', 'DT'), ('sort', 'NN'), ('of', 'IN'), ('justice', 'NN'), (',', ','), ('some', 'DT'), ('manner', 'NN'), ('of', 'IN'), ('peace', 'NN'), ('of', 'IN'), ('mind', 'NN'), (',', ','), ('some', 'DT'), ('questions', 'NNS'), ('answered', 'VBD'), ('and', 'CC'), ('resolutions', 'NNS'), ('made', 'VBN'), ('.', '.'), ('I', 'PRP'), ('do', 'VBP'), (\"n't\", 'RB'), ('want', 'VB'), ('others', 'NNS'), ('to', 'TO'), ('have', 'VB'), ('to', 'TO'), ('go', 'VB'), ('through', 'IN'), ('what', 'WP'), ('myself', 'PRP'), ('and', 'CC'), ('hundreds', 'NNS'), ('of', 'IN'), ('other', 'JJ'), ('commuters', 'NNS'), ('did', 'VBD'), ('on', 'IN'), ('that', 'DT'), ('Summer', 'NN'), (\"'s\", 'POS'), ('day', 'NN'), ('.', '.'), (\"'\", '``'), ('\"', '``'), ('Relatives', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('dead', 'JJ'), ('have', 'VBP'), ('also', 'RB'), ('been', 'VBN'), ('very', 'RB'), ('critical', 'JJ'), ('.', '.'), ('Quoted', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('BBC', 'NNP'), (\"'s\", 'POS'), ('website', 'NN'), (',', ','), ('Saba', 'NNP'), ('Mozakka', 'NNP'), (',', ','), ('the', 'DT'), ('daughter', 'NN'), ('of', 'IN'), ('Behnaz', 'NNP'), ('Mozakka', 'NNP'), (',', ','), ('who', 'WP'), ('died', 'VBD'), ('in', 'IN'), ('the', 'DT'), ('Piccadilly', 'NNP'), ('Line', 'NNP'), ('explosion', 'NN'), (',', ','), ('said', 'VBD'), (':', ':'), ('\"', '``'), ('The', 'DT'), ('families', 'NNS'), ('will', 'MD'), ('be', 'VB'), ('campaigning', 'VBG'), ('for', 'IN'), ('there', 'RB'), ('to', 'TO'), ('be', 'VB'), ('a', 'DT'), ('full', 'JJ'), ('public', 'JJ'), ('inquiry', 'NN'), ('...', ','), ('A', 'DT'), ('narrative', 'NN'), ('of', 'IN'), ('events', 'NNS'), ('will', 'MD'), ('not', 'RB'), ('satisfy', 'VB'), ('anybody', 'NN'), ('.', '.'), ('This', 'DT'), ('is', 'VBZ'), ('not', 'RB'), ('something', 'NN'), ('we', 'PRP'), ('will', 'MD'), ('go', 'VB'), ('away', 'RB'), ('on', 'IN'), ('.', '.'), ('\"', '``'), ('Marie', 'NNP'), ('Fatayi', 'NNP'), ('-', 'HYPH'), ('Williams', 'NNP'), (',', ','), ('whose', 'WP$'), ('son', 'NN'), ('Anthony', 'NNP'), ('was', 'VBD'), ('killed', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('attack', 'NN'), (',', ','), ('told', 'VBD'), ('the', 'DT'), ('BBC', 'NNP'), (':', ':'), ('\"', '``'), ('I', 'PRP'), ('ask', 'VBP'), ('myself', 'PRP'), ('-', ','), ('if', 'IN'), ('there', 'EX'), ('is', 'VBZ'), ('really', 'RB'), ('nothing', 'NN'), ('to', 'TO'), ('hide', 'VB'), ('then', 'RB'), ('why', 'WRB'), ('shy', 'VBP'), ('away', 'RB'), ('from', 'IN'), ('a', 'DT'), ('public', 'JJ'), ('inquiry', 'NN'), ('?', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('the', 'DT'), ('only', 'JJ'), ('real', 'JJ'), ('way', 'NN'), ('that', 'WDT'), ('we', 'PRP'), ('can', 'MD'), ('truly', 'RB'), ('get', 'VB'), ('things', 'NNS'), ('discussed', 'VBN'), ('and', 'CC'), ('see', 'VB'), ('for', 'IN'), ('ourselves', 'PRP'), ('what', 'WP'), ('happened', 'VBD'), ('and', 'CC'), ('what', 'WP'), ('lessons', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('learnt', 'VBN'), ('and', 'CC'), ('whether', 'IN'), ('we', 'PRP'), ('are', 'VBP'), ('better', 'RBR'), ('prepared', 'VBN'), ('now', 'RB'), ('than', 'IN'), ('on', 'IN'), ('7', 'CD'), ('July', 'NNP'), ('...', ':'), ('I', 'PRP'), ('have', 'VBP'), ('a', 'DT'), ('son', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('killed', 'VBN'), ('and', 'CC'), ('is', 'VBZ'), ('never', 'RB'), ('going', 'VBG'), ('to', 'TO'), ('come', 'VB'), ('back', 'RB'), ('.', '.'), ('Nobody', 'NN'), ('is', 'VBZ'), ('going', 'VBG'), ('to', 'TO'), ('tell', 'VB'), ('me', 'PRP'), ('that', 'DT'), ('[', '-LRB-'), ('an', 'DT'), ('inquiry', 'NN'), (']', '-RRB-'), ('is', 'VBZ'), ('a', 'DT'), ('waste', 'NN'), ('of', 'IN'), ('police', 'NN'), ('time', 'NN'), ('.', '.'), ('\"', '``'), ('The', 'DT'), ('survivors', 'NNS'), (\"'\", 'POS'), ('petition', 'NN'), ('has', 'VBZ'), ('so', 'RB'), ('far', 'RB'), ('gathered', 'VBN'), ('over', 'IN'), ('100', 'CD'), ('signatures', 'NNS'), ('.', '.'), ('The', 'DT'), ('British', 'JJ'), ('government', 'NN'), ('has', 'VBZ'), ('given', 'VBN'), ('no', 'DT'), ('response', 'NN'), ('as', 'IN'), ('yet', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = nlp_corenlp.pos_tag(text_0)\n",
    "print('Part of Speech:', nlp_corenlp.pos_tag(text_0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f1beadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency Parsing: [('ROOT', 0, 4), ('compound', 3, 1), ('compound', 3, 2), ('nsubj', 4, 3), ('obj', 4, 5), ('case', 8, 6), ('amod', 8, 7), ('nmod', 5, 8), ('obl:tmod', 4, 9), ('punct', 4, 10), ('compound', 15, 11), ('nummod', 11, 12), ('punct', 11, 13), ('nummod', 11, 14), ('nsubj', 21, 15), ('case', 19, 16), ('det', 19, 17), ('compound', 19, 18), ('nmod', 15, 19), ('aux', 21, 20), ('ccomp', 4, 21), ('det', 24, 22), ('amod', 24, 23), ('obj', 21, 24), ('mark', 26, 25), ('xcomp', 21, 26), ('case', 29, 27), ('nmod:poss', 29, 28), ('obl', 26, 29), ('punct', 4, 30), ('cc', 32, 31), ('conj', 4, 32), ('compound:prt', 32, 33), ('det', 36, 34), ('amod', 36, 35), ('obj', 32, 36), ('acl', 36, 37), ('case', 42, 38), ('det', 42, 39), ('amod', 42, 40), ('compound', 42, 41), ('obl', 37, 42), ('case', 45, 43), ('det', 45, 44), ('obl', 37, 45), ('punct', 4, 46), ('ROOT', 0, 4), ('nummod', 2, 1), ('nsubj:pass', 4, 2), ('aux:pass', 4, 3), ('cc', 8, 5), ('dep', 8, 6), ('advmod', 8, 7), ('conj', 4, 8), ('case', 11, 9), ('compound', 11, 10), ('obl', 4, 11), ('nummod', 11, 12), ('advmod', 17, 13), ('nummod', 16, 14), ('compound', 16, 15), ('nsubj', 17, 16), ('advcl', 4, 17), ('obj', 17, 18), ('compound:prt', 17, 19), ('case', 25, 20), ('nummod', 25, 21), ('amod', 25, 22), ('compound', 25, 23), ('compound', 25, 24), ('obl', 17, 25), ('cc', 29, 26), ('det', 29, 27), ('amod', 29, 28), ('conj', 25, 29), ('punct', 4, 30), ('ROOT', 0, 7), ('advmod', 3, 1), ('det', 3, 2), ('obl:tmod', 7, 3), ('det', 6, 4), ('amod', 6, 5), ('nsubj', 7, 6), ('obj', 7, 8), ('case', 12, 9), ('det', 12, 10), ('compound', 12, 11), ('nmod', 8, 12), ('punct', 7, 13), ('dep', 7, 14), ('mark', 22, 15), ('det:predet', 18, 16), ('det', 18, 17), ('nsubj', 22, 18), ('aux', 22, 19), ('cop', 22, 20), ('advmod', 22, 21), ('ccomp', 14, 22), ('punct', 22, 23), ('conj', 22, 24), ('advmod', 26, 25), ('advmod', 24, 26), ('punct', 22, 27), ('cc', 31, 28), ('cop', 31, 29), ('det', 31, 30), ('conj', 22, 31), ('case', 34, 32), ('nmod:poss', 34, 33), ('nmod', 31, 34), ('mark', 36, 35), ('acl', 34, 36), ('obj', 36, 37), ('punct', 7, 38), ('ROOT', 0, 6), ('advmod', 6, 1), ('punct', 6, 2), ('det', 4, 3), ('nsubj', 6, 4), ('aux', 6, 5), ('mark', 8, 7), ('xcomp', 6, 8), ('advmod', 8, 9), ('det', 12, 10), ('punct', 12, 11), ('obj', 8, 12), ('case', 14, 13), ('nmod', 12, 14), ('punct', 12, 15), ('punct', 6, 16), ('ROOT', 0, 6), ('cc', 6, 1), ('nsubj', 6, 2), ('case', 5, 3), ('det', 5, 4), ('nmod', 2, 5), ('mark', 13, 7), ('det', 11, 8), ('advmod', 10, 9), ('amod', 11, 10), ('nsubj', 13, 11), ('aux', 13, 12), ('ccomp', 6, 13), ('amod', 15, 14), ('obj', 13, 15), ('nsubj', 18, 16), ('aux', 18, 17), ('acl:relcl', 15, 18), ('obj', 18, 19), ('det', 21, 20), ('obj', 19, 21), ('case', 24, 22), ('amod', 24, 23), ('nmod', 21, 24), ('punct', 19, 25), ('cc', 27, 26), ('conj', 19, 27), ('det', 30, 28), ('compound', 30, 29), ('obj', 27, 30), ('case', 34, 31), ('det', 34, 32), ('compound', 34, 33), ('nmod', 30, 34), ('punct', 6, 35), ('ROOT', 0, 29), ('det', 2, 1), ('nsubj:pass', 29, 2), ('punct', 2, 3), ('case', 7, 4), ('fixed', 4, 5), ('compound', 7, 6), ('nmod', 2, 7), ('punct', 7, 8), ('det', 10, 9), ('dep', 7, 10), ('punct', 7, 11), ('punct', 7, 12), ('nsubj', 16, 13), ('aux', 16, 14), ('cop', 16, 15), ('acl:relcl', 7, 16), ('case', 21, 17), ('amod', 21, 18), ('det', 21, 19), ('compound', 21, 20), ('obl', 16, 21), ('case', 25, 22), ('nmod:poss', 25, 23), ('amod', 25, 24), ('obl', 16, 25), ('punct', 29, 26), ('aux', 29, 27), ('aux:pass', 29, 28), ('case', 35, 30), ('det', 32, 31), ('nmod:poss', 35, 32), ('case', 32, 33), ('amod', 35, 34), ('obl', 29, 35), ('case', 39, 36), ('det', 39, 37), ('punct', 39, 38), ('nmod', 35, 39), ('punct', 39, 40), ('punct', 29, 41), ('ROOT', 0, 26), ('nsubj', 26, 1), ('case', 4, 2), ('det', 4, 3), ('obl', 1, 4), ('nsubj', 6, 5), ('ccomp', 1, 6), ('mark', 8, 7), ('xcomp', 6, 8), ('obj', 8, 9), ('punct', 1, 10), ('cc', 12, 11), ('conj', 1, 12), ('punct', 1, 13), ('acl', 1, 14), ('case', 16, 15), ('obl', 14, 16), ('case', 19, 17), ('det', 19, 18), ('obl', 14, 19), ('case', 22, 20), ('compound', 22, 21), ('nmod', 19, 22), ('punct', 22, 23), ('compound', 25, 24), ('appos', 22, 25), ('punct', 26, 27), ('punct', 26, 28), ('advmod', 34, 29), ('mark', 34, 30), ('nsubj', 34, 31), ('aux', 34, 32), ('advmod', 34, 33), ('dep', 40, 34), ('det', 36, 35), ('obj', 34, 36), ('punct', 40, 37), ('aux', 40, 38), ('advmod', 40, 39), ('ccomp', 26, 40), ('det', 42, 41), ('obj', 40, 42), ('punct', 40, 43), ('dep', 40, 44), ('nsubj', 46, 45), ('ccomp', 44, 46), ('det', 48, 47), ('obj', 46, 48), ('advmod', 56, 49), ('punct', 56, 50), ('compound', 52, 51), ('dep', 56, 52), ('punct', 56, 53), ('nsubj', 56, 54), ('cop', 56, 55), ('dep', 48, 56), ('punct', 56, 57), ('advmod', 59, 58), ('appos', 56, 59), ('punct', 56, 60), ('nsubj', 63, 61), ('aux', 63, 62), ('dep', 56, 63), ('det', 65, 64), ('obj', 63, 65), ('case', 67, 66), ('nmod', 65, 67), ('punct', 63, 68), ('mark', 75, 69), ('det', 71, 70), ('nsubj', 75, 71), ('case', 74, 72), ('amod', 74, 73), ('nmod', 71, 74), ('advcl', 63, 75), ('nsubj', 77, 76), ('ccomp', 75, 77), ('punct', 63, 78), ('advmod', 81, 79), ('advmod', 81, 80), ('dep', 63, 81), ('punct', 63, 82), ('nsubj', 84, 83), ('parataxis', 63, 84), ('det', 86, 85), ('obj', 84, 86), ('case', 89, 87), ('det', 89, 88), ('nmod', 86, 89), ('punct', 63, 90), ('det', 92, 91), ('obj', 63, 92), ('punct', 92, 93), ('det', 95, 94), ('appos', 92, 95), ('det', 97, 96), ('obl:tmod', 95, 97), ('punct', 92, 98), ('advmod', 100, 99), ('dep', 92, 100), ('nsubj', 102, 101), ('ccomp', 100, 102), ('nsubj', 104, 103), ('ccomp', 102, 104), ('nmod:poss', 106, 105), ('obj', 104, 106), ('cc', 109, 107), ('advmod', 109, 108), ('conj', 102, 109), ('nsubj', 111, 110), ('ccomp', 109, 111), ('mark', 116, 112), ('nsubj:pass', 116, 113), ('aux', 116, 114), ('aux:pass', 116, 115), ('ccomp', 111, 116), ('case', 120, 117), ('det', 120, 118), ('punct', 120, 119), ('obl', 116, 120), ('mark', 123, 121), ('nsubj', 123, 122), ('acl', 120, 123), ('punct', 123, 124), ('punct', 116, 125), ('mark', 130, 126), ('fixed', 126, 127), ('nsubj', 130, 128), ('cop', 130, 129), ('advcl', 116, 130), ('mark', 133, 131), ('aux:pass', 133, 132), ('xcomp', 130, 133), ('case', 136, 134), ('det', 136, 135), ('obl', 133, 136), ('punct', 26, 137), ('ROOT', 0, 2), ('nsubj', 2, 1), ('nsubj', 4, 3), ('ccomp', 2, 4), ('punct', 2, 5), ('nsubj', 7, 6), ('parataxis', 2, 7), ('mark', 9, 8), ('xcomp', 7, 9), ('dep', 9, 10), ('punct', 2, 11), ('ROOT', 0, 1), ('compound', 3, 2), ('nsubj', 5, 3), ('advmod', 5, 4), ('dep', 1, 5), ('det', 7, 6), ('obj', 5, 7), ('case', 10, 8), ('amod', 10, 9), ('nmod', 7, 10), ('punct', 5, 11), ('punct', 5, 12), ('nsubj:pass', 16, 13), ('aux:pass', 16, 14), ('advmod', 16, 15), ('parataxis', 5, 16), ('mark', 24, 17), ('nsubj', 24, 18), ('cop', 24, 19), ('det', 24, 20), ('amod', 23, 21), ('compound', 23, 22), ('compound', 24, 23), ('ccomp', 16, 24), ('obj', 24, 25), ('aux', 28, 26), ('advmod', 28, 27), ('dep', 24, 28), ('punct', 28, 29), ('case', 31, 30), ('obl', 28, 31), ('det', 33, 32), ('amod', 31, 33), ('advmod', 33, 34), ('aux', 38, 35), ('cop', 38, 36), ('det', 38, 37), ('dep', 28, 38), ('punct', 5, 39), ('ROOT', 0, 2), ('nsubj', 2, 1), ('punct', 2, 3), ('nsubj', 5, 4), ('parataxis', 2, 5), ('obj', 5, 6), ('nsubj', 8, 7), ('parataxis', 5, 8), ('cc', 13, 9), ('nsubj', 13, 10), ('aux', 13, 11), ('advmod', 13, 12), ('conj', 8, 13), ('punct', 2, 14), ('ROOT', 0, 4), ('nsubj', 4, 1), ('aux', 4, 2), ('advmod', 4, 3), ('det', 6, 5), ('obj', 4, 6), ('case', 8, 7), ('obl', 4, 8), ('cc', 13, 9), ('advmod', 13, 10), ('det', 12, 11), ('nsubj', 13, 12), ('conj', 4, 13), ('punct', 4, 14), ('ROOT', 0, 4), ('punct', 4, 1), ('punct', 4, 2), ('punct', 4, 3), ('punct', 4, 5), ('punct', 4, 6), ('mark', 14, 7), ('nsubj', 14, 8), ('advmod', 8, 9), ('punct', 8, 10), ('det', 12, 11), ('appos', 8, 12), ('aux', 14, 13), ('advcl', 26, 14), ('advmod', 21, 15), ('nsubj:pass', 21, 16), ('case', 19, 17), ('det', 19, 18), ('nmod', 16, 19), ('aux:pass', 21, 20), ('xcomp', 14, 21), ('case', 23, 22), ('obl', 21, 23), ('punct', 26, 24), ('nsubj', 26, 25), ('dep', 4, 26), ('punct', 26, 27), ('nsubj', 31, 28), ('case', 30, 29), ('nmod', 28, 30), ('ccomp', 26, 31), ('advmod', 31, 32), ('punct', 4, 33), ('ROOT', 0, 2), ('nsubj', 2, 1), ('expl', 4, 3), ('ccomp', 2, 4), ('compound', 6, 5), ('nsubj', 4, 6), ('case', 8, 7), ('nmod', 6, 8), ('case', 11, 9), ('fixed', 9, 10), ('nmod', 8, 11), ('punct', 2, 12), ('ROOT', 0, 17), ('mark', 5, 1), ('det', 4, 2), ('compound', 4, 3), ('nsubj', 5, 4), ('advcl', 17, 5), ('det', 8, 6), ('amod', 8, 7), ('obj', 5, 8), ('case', 11, 9), ('det', 11, 10), ('obl', 5, 11), ('punct', 17, 12), ('nsubj:pass', 17, 13), ('aux', 17, 14), ('aux:pass', 17, 15), ('advmod', 17, 16), ('case', 20, 18), ('det', 20, 19), ('obl', 17, 20), ('acl', 20, 21), ('case', 23, 22), ('obl', 21, 23), ('advmod', 21, 24), ('punct', 17, 25), ('ROOT', 0, 19), ('punct', 8, 1), ('punct', 8, 2), ('punct', 8, 3), ('compound', 8, 4), ('punct', 8, 5), ('det', 8, 6), ('amod', 8, 7), ('nsubj', 19, 8), ('punct', 8, 9), ('acl', 8, 10), ('case', 17, 11), ('det', 17, 12), ('punct', 17, 13), ('compound', 15, 14), ('compound', 17, 15), ('punct', 17, 16), ('obl', 10, 17), ('punct', 8, 18), ('punct', 19, 20), ('punct', 19, 21), ('punct', 38, 22), ('advmod', 25, 23), ('nsubj', 25, 24), ('advcl', 38, 25), ('det', 30, 26), ('compound', 29, 27), ('punct', 29, 28), ('compound', 30, 29), ('iobj', 25, 30), ('amod', 32, 31), ('dep', 30, 32), ('case', 35, 33), ('det', 35, 34), ('nmod', 32, 35), ('nsubj:pass', 38, 36), ('aux:pass', 38, 37), ('ccomp', 19, 38), ('case', 41, 39), ('det', 41, 40), ('obl', 38, 41), ('case', 44, 42), ('det', 44, 43), ('nmod', 41, 44), ('punct', 38, 45), ('nsubj', 49, 46), ('cop', 49, 47), ('nmod:poss', 49, 48), ('parataxis', 38, 49), ('punct', 38, 50), ('nmod:poss', 52, 51), ('dep', 38, 52), ('punct', 52, 53), ('nmod:poss', 55, 54), ('appos', 52, 55), ('punct', 19, 56), ('ROOT', 0, 5), ('nsubj', 5, 1), ('cop', 5, 2), ('advmod', 5, 3), ('det', 5, 4), ('nsubj:pass', 8, 6), ('aux:pass', 8, 7), ('acl:relcl', 5, 8), ('cc', 10, 9), ('conj', 8, 10), ('case', 15, 11), ('det', 15, 12), ('advmod', 14, 13), ('amod', 15, 14), ('obl', 8, 15), ('dep', 20, 16), ('nsubj', 20, 17), ('aux', 20, 18), ('advmod', 20, 19), ('ccomp', 8, 20), ('case', 26, 21), ('punct', 26, 22), ('nsubj', 26, 23), ('cop', 26, 24), ('det', 26, 25), ('obl', 20, 26), ('nsubj:pass', 29, 27), ('aux:pass', 29, 28), ('acl:relcl', 26, 29), ('cc', 31, 30), ('conj', 29, 31), ('mark', 34, 32), ('nsubj', 34, 33), ('advcl', 29, 34), ('nummod', 36, 35), ('obj', 34, 36), ('case', 41, 37), ('nmod:poss', 39, 38), ('nmod:poss', 41, 39), ('case', 39, 40), ('obl', 34, 41), ('advmod', 45, 42), ('nsubj:pass', 45, 43), ('aux:pass', 45, 44), ('acl:relcl', 41, 45), ('cc', 50, 46), ('compound', 48, 47), ('dep', 50, 48), ('nsubj', 50, 49), ('conj', 45, 50), ('advcl', 50, 51), ('dep', 51, 52), ('nsubj', 52, 53), ('amod', 53, 54), ('mark', 59, 55), ('obj', 59, 56), ('nsubj', 59, 57), ('aux', 59, 58), ('advcl', 54, 59), ('amod', 61, 60), ('obj', 59, 61), ('case', 65, 62), ('amod', 65, 63), ('amod', 65, 64), ('nmod', 61, 65), ('obj', 68, 66), ('nsubj', 68, 67), ('acl:relcl', 65, 68), ('case', 72, 69), ('nmod:poss', 72, 70), ('compound', 72, 71), ('obl', 68, 72), ('dep', 68, 73), ('punct', 5, 74), ('ROOT', 0, 4), ('nsubj', 4, 1), ('cop', 4, 2), ('det', 4, 3), ('case', 6, 5), ('nmod', 4, 6), ('nsubj', 8, 7), ('parataxis', 4, 8), ('advmod', 11, 9), ('nsubj', 11, 10), ('advcl', 8, 11), ('case', 15, 12), ('det', 15, 13), ('compound', 15, 14), ('obl', 11, 15), ('case', 19, 16), ('nmod:poss', 19, 17), ('amod', 19, 18), ('nmod', 15, 19), ('punct', 4, 20), ('ROOT', 0, 3), ('nsubj', 3, 1), ('cop', 3, 2), ('case', 5, 4), ('nmod', 3, 5), ('nsubj:pass', 8, 6), ('aux:pass', 8, 7), ('acl:relcl', 5, 8), ('punct', 8, 9), ('advmod', 12, 10), ('nsubj', 12, 11), ('advcl', 8, 12), ('compound:prt', 12, 13), ('case', 16, 14), ('det', 16, 15), ('obl', 12, 16), ('case', 19, 17), ('det', 19, 18), ('nmod', 16, 19), ('case', 22, 20), ('det', 22, 21), ('nmod', 16, 22), ('case', 24, 23), ('nmod', 22, 24), ('punct', 12, 25), ('nsubj', 27, 26), ('parataxis', 12, 27), ('mark', 30, 28), ('aux:pass', 30, 29), ('xcomp', 27, 30), ('advmod', 35, 31), ('nsubj:pass', 35, 32), ('aux:pass', 35, 33), ('advmod', 35, 34), ('ccomp', 30, 35), ('case', 37, 36), ('obl', 35, 37), ('cc', 40, 38), ('nsubj', 40, 39), ('conj', 35, 40), ('mark', 43, 41), ('aux:pass', 43, 42), ('xcomp', 40, 43), ('case', 46, 44), ('amod', 46, 45), ('obl', 43, 46), ('case', 48, 47), ('nmod', 46, 48), ('case', 50, 49), ('nmod', 48, 50), ('aux', 53, 51), ('aux:pass', 53, 52), ('dep', 3, 53), ('mark', 57, 54), ('nsubj', 57, 55), ('aux', 57, 56), ('ccomp', 53, 57), ('case', 59, 58), ('obl', 57, 59), ('case', 63, 60), ('det', 63, 61), ('amod', 63, 62), ('obl', 57, 63), ('cc', 70, 64), ('case', 67, 65), ('det', 67, 66), ('obl', 70, 67), ('nsubj', 70, 68), ('cop', 70, 69), ('conj', 63, 70), ('punct', 3, 71), ('ROOT', 0, 4), ('advmod', 4, 1), ('punct', 4, 2), ('nsubj', 4, 3), ('det', 6, 5), ('obj', 4, 6), ('case', 8, 7), ('nmod', 6, 8), ('punct', 4, 9), ('det', 11, 10), ('dep', 19, 11), ('case', 13, 12), ('nmod', 11, 13), ('case', 15, 14), ('nmod', 13, 15), ('punct', 19, 16), ('det', 18, 17), ('nsubj', 19, 18), ('parataxis', 4, 19), ('cc', 22, 20), ('nsubj', 22, 21), ('conj', 19, 22), ('punct', 4, 23), ('ROOT', 0, 4), ('nsubj', 4, 1), ('aux', 4, 2), ('advmod', 4, 3), ('obj', 4, 5), ('mark', 7, 6), ('xcomp', 4, 7), ('mark', 9, 8), ('ccomp', 7, 9), ('mark', 18, 10), ('obj', 18, 11), ('nsubj', 18, 12), ('cc', 14, 13), ('conj', 12, 14), ('case', 17, 15), ('amod', 17, 16), ('nmod', 14, 17), ('advcl', 9, 18), ('case', 23, 19), ('det', 21, 20), ('nmod:poss', 23, 21), ('case', 21, 22), ('obl', 18, 23), ('punct', 4, 24), ('ROOT', 0, 11), ('punct', 11, 1), ('punct', 3, 2), ('nsubj', 11, 3), ('case', 6, 4), ('det', 6, 5), ('nmod', 3, 6), ('aux', 11, 7), ('advmod', 11, 8), ('cop', 11, 9), ('advmod', 11, 10), ('punct', 11, 12), ('ROOT', 0, 25), ('nsubj', 25, 1), ('case', 6, 2), ('det', 4, 3), ('nmod:poss', 6, 4), ('case', 4, 5), ('obl', 1, 6), ('punct', 6, 7), ('compound', 9, 8), ('appos', 6, 9), ('punct', 6, 10), ('det', 12, 11), ('appos', 6, 12), ('case', 15, 13), ('compound', 15, 14), ('nmod', 12, 15), ('punct', 6, 16), ('nsubj', 18, 17), ('acl:relcl', 6, 18), ('case', 23, 19), ('det', 23, 20), ('compound', 22, 21), ('compound', 23, 22), ('obl', 18, 23), ('punct', 6, 24), ('punct', 25, 26), ('punct', 25, 27), ('det', 29, 28), ('nsubj', 32, 29), ('aux', 32, 30), ('aux', 32, 31), ('ccomp', 25, 32), ('mark', 40, 33), ('nsubj', 40, 34), ('mark', 40, 35), ('cop', 40, 36), ('det', 40, 37), ('amod', 40, 38), ('amod', 40, 39), ('advcl', 32, 40), ('punct', 40, 41), ('det', 43, 42), ('nsubj', 48, 43), ('case', 45, 44), ('nmod', 43, 45), ('aux', 48, 46), ('advmod', 48, 47), ('parataxis', 40, 48), ('obj', 48, 49), ('punct', 25, 50), ('ROOT', 0, 4), ('nsubj', 4, 1), ('cop', 4, 2), ('advmod', 4, 3), ('nsubj', 7, 5), ('aux', 7, 6), ('parataxis', 4, 7), ('advmod', 7, 8), ('advmod', 7, 9), ('punct', 4, 10), ('ROOT', 0, 16), ('punct', 16, 1), ('compound', 5, 2), ('compound', 5, 3), ('punct', 5, 4), ('nsubj', 16, 5), ('punct', 5, 6), ('nmod:poss', 8, 7), ('nsubj:pass', 11, 8), ('appos', 8, 9), ('aux:pass', 11, 10), ('acl:relcl', 5, 11), ('case', 14, 12), ('det', 14, 13), ('obl', 11, 14), ('punct', 16, 15), ('det', 18, 17), ('obj', 16, 18), ('punct', 16, 19), ('punct', 16, 20), ('nsubj', 22, 21), ('ccomp', 16, 22), ('obj', 22, 23), ('punct', 22, 24), ('mark', 27, 25), ('expl', 27, 26), ('advcl', 22, 27), ('advmod', 27, 28), ('nsubj', 31, 29), ('mark', 31, 30), ('ccomp', 27, 31), ('advmod', 31, 32), ('advmod', 34, 33), ('dep', 31, 34), ('advmod', 34, 35), ('case', 39, 36), ('det', 39, 37), ('amod', 39, 38), ('obl', 35, 39), ('punct', 16, 40), ('ROOT', 0, 6), ('nsubj', 6, 1), ('cop', 6, 2), ('det', 6, 3), ('amod', 6, 4), ('amod', 6, 5), ('advmod', 11, 7), ('nsubj', 11, 8), ('aux', 11, 9), ('advmod', 11, 10), ('dep', 6, 11), ('nsubj', 13, 12), ('ccomp', 11, 13), ('cc', 15, 14), ('conj', 13, 15), ('case', 17, 16), ('obl', 13, 17), ('nsubj', 19, 18), ('ccomp', 13, 19), ('cc', 25, 20), ('obj', 25, 21), ('nsubj:pass', 25, 22), ('aux', 25, 23), ('aux:pass', 25, 24), ('conj', 19, 25), ('cc', 31, 26), ('mark', 31, 27), ('nsubj:pass', 31, 28), ('aux:pass', 31, 29), ('advmod', 31, 30), ('conj', 19, 31), ('advmod', 31, 32), ('case', 36, 33), ('case', 36, 34), ('nummod', 36, 35), ('obl', 31, 36), ('punct', 6, 37), ('nsubj', 39, 38), ('parataxis', 6, 39), ('det', 41, 40), ('obj', 39, 41), ('nsubj:pass', 44, 42), ('aux:pass', 44, 43), ('acl:relcl', 41, 44), ('cc', 48, 45), ('aux', 48, 46), ('advmod', 48, 47), ('conj', 44, 48), ('mark', 50, 49), ('xcomp', 48, 50), ('advmod', 50, 51), ('punct', 6, 52), ('ROOT', 0, 3), ('nsubj', 3, 1), ('aux', 3, 2), ('mark', 5, 4), ('xcomp', 3, 5), ('iobj', 5, 6), ('obj', 5, 7), ('punct', 10, 8), ('det', 10, 9), ('nsubj', 14, 10), ('punct', 10, 11), ('cop', 14, 12), ('det', 14, 13), ('parataxis', 3, 14), ('case', 17, 15), ('compound', 17, 16), ('nmod', 14, 17), ('punct', 3, 18), ('ROOT', 0, 1), ('det', 3, 2), ('nmod:poss', 5, 3), ('case', 3, 4), ('nsubj', 9, 5), ('aux', 9, 6), ('advmod', 8, 7), ('advmod', 9, 8), ('dep', 1, 9), ('advmod', 11, 10), ('nummod', 12, 11), ('obj', 9, 12), ('punct', 9, 13), ('ROOT', 0, 5), ('det', 3, 1), ('amod', 3, 2), ('nsubj', 5, 3), ('aux', 5, 4), ('det', 7, 6), ('obj', 5, 7), ('case', 9, 8), ('advcl', 5, 9), ('punct', 5, 10)]\n"
     ]
    }
   ],
   "source": [
    "dependency_parse = nlp_corenlp.dependency_parse(text_0)\n",
    "print('Dependency Parsing:', nlp_corenlp.dependency_parse(text_0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b260aa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London bomb survivors launch campaign for public inquiry\n",
      "\n",
      "Sunday, December 18, 2005\n",
      "\n",
      "Survivors of the London Bombings have urged the British public to write to their MPs, and set up an online petition calling for an independent Public Inquiry into the attacks.\n",
      "\n",
      "52 people were killed and hundreds more injured on July 7th 2005 when four suicide bombers blew themselves up on three separate London Underground trains and a public bus.\n",
      "\n",
      "Earlier this week the British government rejected calls for a Public Inquiry, arguing that such an investigation would be too expensive, take too long, and be a distraction from their efforts to combat terrorism. Instead, the government has offered to put together a \"narrative of events\".\n",
      "\n",
      "But survivors of the attack argue that a fully comprehensive investigation could teach valuable lessons which may help reduce the likelihood of future attacks, and improve the response capabilities of the emergency services.\n",
      "\n",
      "Some survivors, such as Rachel North (a pseudonym), who has been active in organising a support group for her fellow victims, have been angered by the government's alternative proposal of a \"narrative\". Writing on the weblog she started to help her, and others, come to terms with the aftermath of July 7th, Ms North says:\n",
      "\n",
      "\"Even if you don't like the questions, don't like the answers, think you know the answers already, Mr Blair, it is us, not you, who are paying the cost for this... If the cost of answering questions makes you squirm, then too bad... We run the risks on the trains, the buses, the streets each day... How dare you presume you know our questions and how dare you presume that they can be answered by a 'narrative of what happened', as if we are children to be placated with a story. I know what happened, I want to know why.\"\n",
      "\n",
      "Ms North also quotes a number of other survivors:\n",
      "\n",
      "\"We are constantly reminded that this is the worst peace time bombing London has ever seen, for something that bad there should be an inquiry. People died, families lost someone they loved and hundreds are still suffering. You can't put a price on that but apparently the government can.\" - \"Fiona\"\n",
      "\n",
      "\"If nothing else, an enquiry would make sure some of these lessons were learnt in case, God forbid, anything like this happened again. I thought there were plansin place for emergencies such as this. Whilst the emergency services did a fantastic job on the day, I have been stunningly underwhelmed by the support offered to victims since.\" - \"Pauline\"\n",
      "\n",
      "An anonymous survivor, writing on the \"Yorkshire lass\" website, says:\n",
      "\n",
      "\"'When I watched the Al-Qaeda video declaring Jihad against the UK I was haunted by the familiarity of the voice, it was my voice, my accent, my dialect. This is not a man who was recruited and trained in some far off country that I have barely heard of, this was a man who was recruited and trained while he lived 20 minutes from my mother's home where I was born and raised.The words he spoke of are words similar to what I have heard many times from disillusioned young men that I studied for my A Levels with. They are the words of hatred I overheard when I worked as a support worker at my local college. They were words of students who were educated... when someone follows through with the actions of those opinions to the detriment of others, questions need to be asked why preventions were not put in place and this needs to be done by public inquiry for peace of mind.I have been told that I am looking for justice in the wrong place and in some way that is right. However, I want some sort of justice, some manner of peace of mind, some questions answered and resolutions made. I don't want others to have to go through what myself and hundreds of other commuters did on that Summer's day.'\"\n",
      "\n",
      "Relatives of the dead have also been very critical. Quoted on the BBC's website, Saba Mozakka, the daughter of Behnaz Mozakka,who died in the Piccadilly Line explosion, said:\n",
      "\n",
      "\"The families will be campaigning for there to be a full public inquiry... A narrative of events will not satisfy anybody. This is not something we will go away on.\"\n",
      "\n",
      "Marie Fatayi-Williams, whose son Anthony was killed in the attack, told the BBC: \"I ask myself - if there is really nothing to hide then why shy away from a public inquiry? It is the only real way that we can truly get things discussed and see for ourselves what happened and what lessons can be learnt and whether we are better prepared now than on 7 July... I have a son who was killed and is never going to come back. Nobody is going to tell me that [an inquiry] is a waste of police time.\"\n",
      "\n",
      "The survivors' petition has so far gathered over 100 signatures. The British government has given no response as yet.\n"
     ]
    }
   ],
   "source": [
    "print(text_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26a4df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coreferences=nlp_corenlp.coref(text_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "096d160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coreference Resolution: [[(1, 1, 4, 'London bomb survivors'), (27, 2, 5, \"The survivors '\")], [(7, 31, 32, 'you'), (7, 45, 46, 'you'), (7, 59, 60, 'you'), (7, 76, 77, 'you'), (7, 101, 102, 'you'), (7, 103, 104, 'you'), (7, 110, 111, 'you')], [(7, 41, 43, 'the answers'), (7, 47, 49, 'the answers')], [(7, 113, 114, 'they'), (9, 13, 14, 'We')], [(16, 33, 34, 'he'), (16, 49, 50, 'he')], [(22, 3, 6, \"the BBC 's\"), (23, 5, 6, 'we'), (24, 17, 19, 'the BBC')], [(6, 6, 8, 'Rachel North'), (6, 23, 24, 'her'), (7, 5, 6, 'she'), (7, 9, 10, 'her'), (7, 24, 26, 'Ms North'), (7, 51, 53, 'Mr Blair'), (8, 1, 2, 'I'), (8, 6, 7, 'I'), (9, 2, 4, 'Ms North')], [(3, 4, 7, 'the British government'), (4, 3, 5, 'the government'), (5, 4, 6, 'the attack'), (6, 31, 34, \"the government 's\"), (11, 11, 13, 'the government'), (24, 13, 15, 'the attack'), (28, 1, 4, 'The British government')], [(1, 11, 20, 'December 18 , 2005 Survivors of the London Bombings'), (1, 28, 29, 'their')], [(7, 56, 57, 'us'), (7, 105, 106, 'our'), (7, 128, 129, 'we'), (11, 1, 2, 'You')], [(15, 43, 45, 'the voice'), (15, 48, 50, 'my voice')], [(15, 26, 31, 'the Al - Qaeda video'), (15, 46, 47, 'it')], [(13, 1, 2, 'I'), (14, 13, 14, 'I'), (15, 24, 25, 'I'), (15, 36, 37, 'I'), (15, 48, 49, 'my'), (15, 51, 52, 'my'), (15, 54, 55, 'my'), (16, 17, 18, 'I'), (16, 38, 39, 'my'), (16, 43, 44, 'I'), (16, 57, 58, 'I'), (16, 67, 68, 'I'), (16, 70, 71, 'my'), (17, 7, 8, 'I'), (17, 10, 11, 'I'), (17, 17, 18, 'my'), (18, 55, 56, 'I'), (19, 3, 4, 'I'), (20, 1, 2, 'I'), (20, 12, 13, 'myself')], [(2, 14, 17, 'four suicide bombers'), (2, 18, 19, 'themselves')], [(17, 1, 2, 'They'), (18, 1, 2, 'They')], [(25, 8, 9, 'we'), (25, 17, 18, 'ourselves'), (25, 28, 29, 'we')], [(9, 18, 19, 'this'), (12, 30, 31, 'this')], [(24, 2, 15, 'Marie Fatayi - Williams , whose son Anthony was killed in the attack'), (24, 21, 22, 'I'), (24, 23, 24, 'myself'), (25, 38, 39, 'I'), (26, 6, 7, 'me')], [(16, 1, 2, 'This'), (16, 23, 24, 'this')], [(10, 4, 5, 'families'), (10, 7, 8, 'they'), (22, 28, 30, 'The families')], [(1, 1, 2, 'London'), (2, 23, 24, 'London'), (9, 25, 26, 'London')], [(5, 32, 35, 'the emergency services'), (14, 2, 5, 'the emergency services')]]\n"
     ]
    }
   ],
   "source": [
    "print('Coreference Resolution:',nlp_corenlp.coref(text_0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "147f955d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coreferences = nlp_corenlp.coref(text_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f6866f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacement of words with same entities\n",
    "def replace_coreferences(coreference_mentions, sents_list):\n",
    "    for mentions in coreference_mentions:\n",
    "        representative_phrase = mentions[0][-1]\n",
    "        for mention_index, mention in enumerate(mentions):\n",
    "            for sent_index, sent in enumerate(sents_list):\n",
    "                if sent == mention[0]:\n",
    "                    start_index = mention[1]\n",
    "                    end_index = start_index + len(mention[3])-1\n",
    "\n",
    "                    sents_list[sent_index] = (\n",
    "                        sents_list[sent_index][:start_index]\n",
    "                        + representative_phrase\n",
    "                        + sents_list[sent_index][end_index +1:]\n",
    "                    )\n",
    "\n",
    "    text_1 = ' '.join(sents_list)\n",
    "    return text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7d9aed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London bomb survivors launch campaign for public inquiry\n",
      "\n",
      "Sunday, December 18, 2005\n",
      "\n",
      "Survivors of the London Bombings have urged the British public to write to their MPs, and set up an online petition calling for an independent Public Inquiry into the attacks. \n",
      "\n",
      "52 people were killed and hundreds more injured on July 7th 2005 when four suicide bombers blew themselves up on three separate London Underground trains and a public bus. \n",
      "\n",
      "Earlier this week the British government rejected calls for a Public Inquiry, arguing that such an investigation would be too expensive, take too long, and be a distraction from their efforts to combat terrorism. Instead, the government has offered to put together a \"narrative of events\". \n",
      "\n",
      "But survivors of the attack argue that a fully comprehensive investigation could teach valuable lessons which may help reduce the likelihood of future attacks, and improve the response capabilities of the emergency services. \n",
      "\n",
      "Some survivors, such as Rachel North (a pseudonym), who has been active in organising a support group for her fellow victims, have been angered by the government's alternative proposal of a \"narrative\". Writing on the weblog she started to help her, and others, come to terms with the aftermath of July 7th, Ms North says:\n",
      "\n",
      "\"Even if you don't like the questions, don't like the answers, think you know the answers already, Mr Blair, it is us, not you, who are paying the cost for this... If the cost of answering questions makes you squirm, then too bad... We run the risks on the trains, the buses, the streets each day... How dare you presume you know our questions and how dare you presume that they can be answered by a 'narrative of what happened', as if we are children to be placated with a story. I know what happened, I want to know why.\" \n",
      "\n",
      "Ms North also quotes a number of other survivors:\n",
      "\n",
      "\"We are constantly reminded that this is the worst peace time bombing London has ever seen, for something that bad there should be an inquiry. People died, families lost someone they loved and hundreds are still suffering. You can't put a price on that but apparently the government can.\" - \" Fiona\"\n",
      "\n",
      "\"If nothing else, an enquiry would make sure some of these lessons were learnt in case, God forbid, anything like this happened again. I thought there were plansin place for emergencies such as this. Whilst the emergency services did a fantastic job on the day, I have been stunningly underwhelmed by the support offered to victims since.\" - \" Pauline\"\n",
      "\n",
      "An anonymous survivor, writing on the \"Yorkshire lass\" website, says:\n",
      "\n",
      "\"'When I watched the Al-Qaeda video declaring Jihad against the UK I was haunted by the familiarity of the voice, it was my voice, my accent, my dialect. This is not a man who was recruited and trained in some far off country that I have barely heard of, this was a man who was recruited and trained while he lived 20 minutes from my mother's home where I was born and raised. The words he spoke of are words similar to what I have heard many times from disillusioned young men that I studied for my A Levels with. They are the words of hatred I overheard when I worked as a support worker at my local college. They were words of students who were educated... when someone follows through with the actions of those opinions to the detriment of others, questions need to be asked why preventions were not put in place and this needs to be done by public inquiry for peace of mind. I have been told that I am looking for justice in the wrong place and in some way that is right. However, I want some sort of justice, some manner of peace of mind, some questions answered and resolutions made. I don't want others to have to go through what myself and hundreds of other commuters did on that Summer's day.'\" \n",
      "\n",
      "Relatives of the dead have also been very critical. Quoted on the BBC's website, Saba Mozakka, the daughter of Behnaz Mozakka,who died in the Piccadilly Line explosion, said:\n",
      "\n",
      "\"The families will be campaigning for there to be a full public inquiry... A narrative of events will not satisfy anybody. This is not something we will go away on.\" \n",
      "\n",
      "Marie Fatayi-Williams, whose son Anthony was killed in the attack, told the BBC: \"I ask myself - if there is really nothing to hide then why shy away from a public inquiry? It is the only real way that we can truly get things discussed and see for ourselves what happened and what lessons can be learnt and whether we are better prepared now than on 7 July... I have a son who was killed and is never going to come back. Nobody is going to tell me that [an inquiry] is a waste of police time.\" \n",
      "\n",
      "The survivors' petition has so far gathered over 100 signatures. The British government has given no response as yet.\n"
     ]
    }
   ],
   "source": [
    "#This is not getting replaced\n",
    "replaced_text = replace_coreferences(coreferences, sents_list)\n",
    "print(replaced_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d9b90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc7798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEXICAL CHAIN FORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f01a1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which define words which are either noun, verb,adjective and adverb\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afa70bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, POS tags are converted into Wordnet Format. Then we are creating a dictionay to store synonymous words or synsets.\n",
    "lexical_chains_dict = {}\n",
    "\n",
    "for sent in sents_list:\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    \n",
    "    for word, pos in tagged_tokens:\n",
    "        wordnet_pos = get_wordnet_pos(pos)\n",
    "        if wordnet_pos:\n",
    "            synsets = wordnet.synsets(word, pos=wordnet_pos)\n",
    "            if synsets:\n",
    "                if synsets[0] in lexical_chains_dict:\n",
    "                    lexical_chains_dict[synsets[0]].append(word)\n",
    "                else:\n",
    "                    lexical_chains_dict[synsets[0]] = [word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5999bc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: Synset('london.n.01'), Words: ['London', 'London', 'London', 'London']\n",
      "Synset: Synset('bomb.n.01'), Words: ['bomb']\n",
      "Synset: Synset('survivor.n.01'), Words: ['survivors', 'Survivors', 'survivors', 'survivors', 'survivors', 'survivor', 'survivors']\n",
      "Synset: Synset('establish.v.01'), Words: ['launch']\n",
      "Synset: Synset('political_campaign.n.01'), Words: ['campaign']\n",
      "Synset: Synset('public.a.01'), Words: ['public', 'public', 'public', 'public', 'public']\n",
      "Synset: Synset('inquiry.n.01'), Words: ['inquiry', 'Inquiry', 'Inquiry', 'inquiry', 'inquiry', 'inquiry', 'inquiry', 'inquiry']\n",
      "Synset: Synset('sunday.n.01'), Words: ['Sunday']\n",
      "Synset: Synset('december.n.01'), Words: ['December']\n",
      "Synset: Synset('bombing.n.01'), Words: ['Bombings']\n",
      "Synset: Synset('have.v.01'), Words: ['have', 'has', 'has', 'have', 'has', 'have', 'have', 'have', 'have', 'have', 'have', 'have', 'has', 'has']\n",
      "Synset: Synset('urge.v.01'), Words: ['urged']\n",
      "Synset: Synset('british.a.01'), Words: ['British', 'British', 'British']\n",
      "Synset: Synset('populace.n.01'), Words: ['public', 'Public', 'Public']\n",
      "Synset: Synset('write.v.01'), Words: ['write', 'Writing', 'writing']\n",
      "Synset: Synset('mononuclear_phagocyte_system.n.01'), Words: ['MPs']\n",
      "Synset: Synset('put.v.01'), Words: ['set', 'put', 'put', 'put']\n",
      "Synset: Synset('up.r.01'), Words: ['up', 'up']\n",
      "Synset: Synset('on-line.a.01'), Words: ['online']\n",
      "Synset: Synset('request.n.01'), Words: ['petition', 'petition']\n",
      "Synset: Synset('name.v.01'), Words: ['calling']\n",
      "Synset: Synset('independent.a.01'), Words: ['independent']\n",
      "Synset: Synset('attack.n.01'), Words: ['attacks', 'attack', 'attacks', 'attack']\n",
      "Synset: Synset('people.n.01'), Words: ['people', 'People']\n",
      "Synset: Synset('be.v.01'), Words: ['were', 'be', 'be', 'been', 'been', 'is', 'are', 'be', 'are', 'be', 'are', 'is', 'be', 'are', 'were', 'were', 'been', 'was', 'was', 'is', 'was', 'was', 'was', 'was', 'are', 'are', 'were', 'were', 'be', 'were', 'be', 'been', 'am', 'is', 'been', 'be', 'be', 'is', 'was', 'is', 'is', 'be', 'are', 'was', 'is', 'is', 'is']\n",
      "Synset: Synset('kill.v.01'), Words: ['killed', 'killed', 'killed']\n",
      "Synset: Synset('hundred.n.01'), Words: ['hundreds', 'hundreds', 'hundreds']\n",
      "Synset: Synset('more.r.01'), Words: ['more']\n",
      "Synset: Synset('injured.a.01'), Words: ['injured']\n",
      "Synset: Synset('july.n.01'), Words: ['July', 'July', 'July']\n",
      "Synset: Synset('suicide.n.01'), Words: ['suicide']\n",
      "Synset: Synset('bomber.n.01'), Words: ['bombers']\n",
      "Synset: Synset('blow.v.01'), Words: ['blew']\n",
      "Synset: Synset('separate.a.01'), Words: ['separate']\n",
      "Synset: Synset('underground.n.01'), Words: ['Underground']\n",
      "Synset: Synset('train.n.01'), Words: ['trains', 'trains']\n",
      "Synset: Synset('bus.n.01'), Words: ['bus', 'buses']\n",
      "Synset: Synset('earlier.r.01'), Words: ['Earlier']\n",
      "Synset: Synset('week.n.01'), Words: ['week']\n",
      "Synset: Synset('government.n.01'), Words: ['government', 'government', 'government', 'government', 'government']\n",
      "Synset: Synset('reject.v.01'), Words: ['rejected']\n",
      "Synset: Synset('call.n.01'), Words: ['calls']\n",
      "Synset: Synset('argue.v.01'), Words: ['arguing']\n",
      "Synset: Synset('probe.n.01'), Words: ['investigation', 'investigation']\n",
      "Synset: Synset('excessively.r.01'), Words: ['too', 'too', 'too']\n",
      "Synset: Synset('expensive.a.01'), Words: ['expensive']\n",
      "Synset: Synset('take.v.01'), Words: ['take']\n",
      "Synset: Synset('long.r.01'), Words: ['long']\n",
      "Synset: Synset('distraction.n.01'), Words: ['distraction']\n",
      "Synset: Synset('attempt.n.01'), Words: ['efforts']\n",
      "Synset: Synset('battle.v.01'), Words: ['combat']\n",
      "Synset: Synset('terrorism.n.01'), Words: ['terrorism']\n",
      "Synset: Synset('alternatively.r.01'), Words: ['Instead']\n",
      "Synset: Synset('offer.v.01'), Words: ['offered', 'offered']\n",
      "Synset: Synset('together.r.01'), Words: ['together']\n",
      "Synset: Synset('narrative.s.01'), Words: ['narrative', 'narrative']\n",
      "Synset: Synset('event.n.01'), Words: ['events', 'events']\n",
      "Synset: Synset('fully.r.01'), Words: ['fully']\n",
      "Synset: Synset('comprehensive.a.01'), Words: ['comprehensive']\n",
      "Synset: Synset('teach.v.01'), Words: ['teach']\n",
      "Synset: Synset('valuable.a.01'), Words: ['valuable']\n",
      "Synset: Synset('lesson.n.01'), Words: ['lessons', 'lessons', 'lessons']\n",
      "Synset: Synset('help.v.01'), Words: ['help', 'help']\n",
      "Synset: Synset('reduce.v.01'), Words: ['reduce']\n",
      "Synset: Synset('likelihood.n.01'), Words: ['likelihood']\n",
      "Synset: Synset('future.a.01'), Words: ['future']\n",
      "Synset: Synset('better.v.02'), Words: ['improve']\n",
      "Synset: Synset('response.n.01'), Words: ['response', 'response']\n",
      "Synset: Synset('capability.n.01'), Words: ['capabilities']\n",
      "Synset: Synset('emergency.n.01'), Words: ['emergency', 'emergencies', 'emergency']\n",
      "Synset: Synset('services.n.01'), Words: ['services', 'services']\n",
      "Synset: Synset('such.s.01'), Words: ['such', 'such']\n",
      "Synset: Synset('rachel.n.01'), Words: ['Rachel']\n",
      "Synset: Synset('north.n.01'), Words: ['North', 'North', 'North']\n",
      "Synset: Synset('pseudonym.n.01'), Words: ['pseudonym']\n",
      "Synset: Synset('active.a.01'), Words: ['active']\n",
      "Synset: Synset('organize.v.04'), Words: ['organising']\n",
      "Synset: Synset('support.n.01'), Words: ['support', 'support', 'support']\n",
      "Synset: Synset('group.n.01'), Words: ['group']\n",
      "Synset: Synset('victim.n.01'), Words: ['victims', 'victims']\n",
      "Synset: Synset('anger.v.01'), Words: ['angered']\n",
      "Synset: Synset('alternate.s.02'), Words: ['alternative']\n",
      "Synset: Synset('proposal.n.01'), Words: ['proposal']\n",
      "Synset: Synset('get_down.v.07'), Words: ['started']\n",
      "Synset: Synset('come.v.01'), Words: ['come', 'come']\n",
      "Synset: Synset('footing.n.01'), Words: ['terms']\n",
      "Synset: Synset('aftermath.n.01'), Words: ['aftermath']\n",
      "Synset: Synset('multiple_sclerosis.n.01'), Words: ['Ms', 'Ms']\n",
      "Synset: Synset('state.v.01'), Words: ['says', 'says', 'told', 'said', 'told', 'tell']\n",
      "Synset: Synset('even.r.01'), Words: ['Even']\n",
      "Synset: Synset('make.v.01'), Words: ['do', 'do', 'makes', 'make', 'did', 'done', 'made', 'do', 'did']\n",
      "Synset: Synset('wish.v.02'), Words: ['like', 'like']\n",
      "Synset: Synset('question.n.01'), Words: ['questions', 'questions', 'questions', 'enquiry', 'questions', 'questions']\n",
      "Synset: Synset('answer.n.01'), Words: ['answers', 'answers']\n",
      "Synset: Synset('think.v.01'), Words: ['think', 'thought']\n",
      "Synset: Synset('know.v.01'), Words: ['know', 'know', 'know', 'know']\n",
      "Synset: Synset('already.r.01'), Words: ['already']\n",
      "Synset: Synset('mister.n.01'), Words: ['Mr']\n",
      "Synset: Synset('blair.n.01'), Words: ['Blair']\n",
      "Synset: Synset('not.r.01'), Words: ['not', 'not', 'not', 'not', 'not']\n",
      "Synset: Synset('pay.v.01'), Words: ['paying']\n",
      "Synset: Synset('cost.n.01'), Words: ['cost', 'cost']\n",
      "Synset: Synset('answer.v.01'), Words: ['answering', 'answered', 'answered']\n",
      "Synset: Synset('writhe.v.01'), Words: ['squirm']\n",
      "Synset: Synset('then.r.01'), Words: ['then', 'then']\n",
      "Synset: Synset('bad.a.01'), Words: ['bad', 'bad']\n",
      "Synset: Synset('run.v.01'), Words: ['run']\n",
      "Synset: Synset('hazard.n.01'), Words: ['risks']\n",
      "Synset: Synset('street.n.01'), Words: ['streets']\n",
      "Synset: Synset('day.n.01'), Words: ['day', 'day', 'day']\n",
      "Synset: Synset('dare.n.01'), Words: ['dare', 'dare']\n",
      "Synset: Synset('assume.v.01'), Words: ['presume', 'presume']\n",
      "Synset: Synset('happen.v.01'), Words: ['happened', 'happened', 'happened', 'happened']\n",
      "Synset: Synset('child.n.01'), Words: ['children']\n",
      "Synset: Synset('pacify.v.01'), Words: ['placated']\n",
      "Synset: Synset('narrative.n.01'), Words: ['story', 'narrative']\n",
      "Synset: Synset('desire.v.01'), Words: ['want', 'want', 'want']\n",
      "Synset: Synset('besides.r.02'), Words: ['also', 'also']\n",
      "Synset: Synset('quote.v.01'), Words: ['quotes', 'Quoted']\n",
      "Synset: Synset('number.n.01'), Words: ['number']\n",
      "Synset: Synset('other.a.01'), Words: ['other', 'other']\n",
      "Synset: Synset('constantly.r.01'), Words: ['constantly']\n",
      "Synset: Synset('remind.v.01'), Words: ['reminded']\n",
      "Synset: Synset('worst.a.01'), Words: ['worst']\n",
      "Synset: Synset('peace.n.01'), Words: ['peace', 'peace', 'peace']\n",
      "Synset: Synset('time.n.01'), Words: ['time', 'time']\n",
      "Synset: Synset('bombard.v.02'), Words: ['bombing']\n",
      "Synset: Synset('ever.r.01'), Words: ['ever']\n",
      "Synset: Synset('see.v.01'), Words: ['seen', 'see']\n",
      "Synset: Synset('die.v.01'), Words: ['died', 'died']\n",
      "Synset: Synset('family.n.01'), Words: ['families', 'families']\n",
      "Synset: Synset('lose.v.01'), Words: ['lost']\n",
      "Synset: Synset('person.n.01'), Words: ['someone', 'someone']\n",
      "Synset: Synset('love.v.01'), Words: ['loved']\n",
      "Synset: Synset('still.r.01'), Words: ['still']\n",
      "Synset: Synset('suffer.v.01'), Words: ['suffering']\n",
      "Synset: Synset('monetary_value.n.01'), Words: ['price']\n",
      "Synset: Synset('apparently.r.01'), Words: ['apparently']\n",
      "Synset: Synset('nothing.n.01'), Words: ['nothing', 'nothing']\n",
      "Synset: Synset('certain.a.02'), Words: ['sure']\n",
      "Synset: Synset('learn.v.01'), Words: ['learnt']\n",
      "Synset: Synset('case.n.01'), Words: ['case']\n",
      "Synset: Synset('god.n.01'), Words: ['God']\n",
      "Synset: Synset('again.r.01'), Words: ['again']\n",
      "Synset: Synset('topographic_point.n.01'), Words: ['place', 'place', 'place']\n",
      "Synset: Synset('antic.s.01'), Words: ['fantastic']\n",
      "Synset: Synset('occupation.n.01'), Words: ['job']\n",
      "Synset: Synset('spectacularly.r.01'), Words: ['stunningly']\n",
      "Synset: Synset('anonymous.a.01'), Words: ['anonymous']\n",
      "Synset: Synset('yorkshire.n.01'), Words: ['Yorkshire']\n",
      "Synset: Synset('lass.n.01'), Words: ['lass']\n",
      "Synset: Synset('web_site.n.01'), Words: ['website', 'website']\n",
      "Synset: Synset('watch.v.01'), Words: ['watched']\n",
      "Synset: Synset('al-qaeda.n.01'), Words: ['Al-Qaeda']\n",
      "Synset: Synset('video.n.01'), Words: ['video']\n",
      "Synset: Synset('declare.v.01'), Words: ['declaring']\n",
      "Synset: Synset('jihad.n.01'), Words: ['Jihad']\n",
      "Synset: Synset('united_kingdom.n.01'), Words: ['UK']\n",
      "Synset: Synset('haunt.v.01'), Words: ['haunted']\n",
      "Synset: Synset('acquaintance.n.01'), Words: ['familiarity']\n",
      "Synset: Synset('voice.n.01'), Words: ['voice', 'voice']\n",
      "Synset: Synset('accent.n.01'), Words: ['accent']\n",
      "Synset: Synset('dialect.n.01'), Words: ['dialect']\n",
      "Synset: Synset('man.n.01'), Words: ['man', 'man']\n",
      "Synset: Synset('enroll.v.01'), Words: ['recruited', 'recruited']\n",
      "Synset: Synset('train.v.01'), Words: ['trained', 'trained']\n",
      "Synset: Synset('far.r.01'), Words: ['far', 'far']\n",
      "Synset: Synset('away.r.01'), Words: ['off', 'away', 'away']\n",
      "Synset: Synset('state.n.04'), Words: ['country']\n",
      "Synset: Synset('barely.r.01'), Words: ['barely']\n",
      "Synset: Synset('hear.v.01'), Words: ['heard', 'heard']\n",
      "Synset: Synset('populate.v.01'), Words: ['lived']\n",
      "Synset: Synset('minutes.n.01'), Words: ['minutes']\n",
      "Synset: Synset('mother.n.01'), Words: ['mother']\n",
      "Synset: Synset('home.n.01'), Words: ['home']\n",
      "Synset: Synset('bear.v.01'), Words: ['born']\n",
      "Synset: Synset('raise.v.01'), Words: ['raised']\n",
      "Synset: Synset('words.n.01'), Words: ['words', 'words', 'words', 'words']\n",
      "Synset: Synset('talk.v.02'), Words: ['spoke']\n",
      "Synset: Synset('similar.a.01'), Words: ['similar']\n",
      "Synset: Synset('many.a.01'), Words: ['many']\n",
      "Synset: Synset('times.n.01'), Words: ['times']\n",
      "Synset: Synset('disillusioned.s.01'), Words: ['disillusioned']\n",
      "Synset: Synset('young.a.01'), Words: ['young']\n",
      "Synset: Synset('work_force.n.01'), Words: ['men']\n",
      "Synset: Synset('analyze.v.01'), Words: ['studied']\n",
      "Synset: Synset('angstrom.n.01'), Words: ['A', 'A']\n",
      "Synset: Synset('degree.n.01'), Words: ['Levels']\n",
      "Synset: Synset('catch.v.14'), Words: ['overheard']\n",
      "Synset: Synset('work.v.01'), Words: ['worked']\n",
      "Synset: Synset('worker.n.01'), Words: ['worker']\n",
      "Synset: Synset('local.a.01'), Words: ['local']\n",
      "Synset: Synset('college.n.01'), Words: ['college']\n",
      "Synset: Synset('student.n.01'), Words: ['students']\n",
      "Synset: Synset('educate.v.01'), Words: ['educated']\n",
      "Synset: Synset('follow.v.01'), Words: ['follows']\n",
      "Synset: Synset('action.n.01'), Words: ['actions']\n",
      "Synset: Synset('opinion.n.01'), Words: ['opinions']\n",
      "Synset: Synset('detriment.n.01'), Words: ['detriment']\n",
      "Synset: Synset('necessitate.v.01'), Words: ['need', 'needs']\n",
      "Synset: Synset('ask.v.01'), Words: ['asked', 'ask']\n",
      "Synset: Synset('prevention.n.01'), Words: ['preventions']\n",
      "Synset: Synset('mind.n.01'), Words: ['mind', 'mind']\n",
      "Synset: Synset('look.v.01'), Words: ['looking']\n",
      "Synset: Synset('justice.n.01'), Words: ['justice', 'justice']\n",
      "Synset: Synset('incorrect.a.01'), Words: ['wrong']\n",
      "Synset: Synset('manner.n.01'), Words: ['way', 'manner', 'way']\n",
      "Synset: Synset('right.a.01'), Words: ['right']\n",
      "Synset: Synset('however.r.01'), Words: ['However']\n",
      "Synset: Synset('kind.n.01'), Words: ['sort']\n",
      "Synset: Synset('resolution.n.01'), Words: ['resolutions']\n",
      "Synset: Synset('travel.v.01'), Words: ['go', 'go', 'going', 'going']\n",
      "Synset: Synset('commuter.n.01'), Words: ['commuters']\n",
      "Synset: Synset('summer.n.01'), Words: ['Summer']\n",
      "Synset: Synset('relative.n.01'), Words: ['Relatives']\n",
      "Synset: Synset('dead.a.01'), Words: ['dead']\n",
      "Synset: Synset('very.r.01'), Words: ['very']\n",
      "Synset: Synset('critical.a.01'), Words: ['critical']\n",
      "Synset: Synset('saba.n.01'), Words: ['Saba']\n",
      "Synset: Synset('daughter.n.01'), Words: ['daughter']\n",
      "Synset: Synset('line.n.01'), Words: ['Line']\n",
      "Synset: Synset('explosion.n.01'), Words: ['explosion']\n",
      "Synset: Synset('campaign.v.01'), Words: ['campaigning']\n",
      "Synset: Synset('full.a.01'), Words: ['full']\n",
      "Synset: Synset('satisfy.v.01'), Words: ['satisfy']\n",
      "Synset: Synset('son.n.01'), Words: ['son', 'son']\n",
      "Synset: Synset('antony.n.01'), Words: ['Anthony']\n",
      "Synset: Synset('truly.r.01'), Words: ['really']\n",
      "Synset: Synset('hide.v.01'), Words: ['hide']\n",
      "Synset: Synset('shy.v.01'), Words: ['shy']\n",
      "Synset: Synset('lone.s.03'), Words: ['only']\n",
      "Synset: Synset('real.a.01'), Words: ['real']\n",
      "Synset: Synset('get.v.01'), Words: ['get']\n",
      "Synset: Synset('things.n.01'), Words: ['things']\n",
      "Synset: Synset('discourse.v.01'), Words: ['discussed']\n",
      "Synset: Synset('better.r.01'), Words: ['better']\n",
      "Synset: Synset('fix.v.12'), Words: ['prepared']\n",
      "Synset: Synset('now.r.01'), Words: ['now']\n",
      "Synset: Synset('never.r.01'), Words: ['never']\n",
      "Synset: Synset('back.r.01'), Words: ['back']\n",
      "Synset: Synset('cipher.n.04'), Words: ['Nobody']\n",
      "Synset: Synset('waste.n.01'), Words: ['waste']\n",
      "Synset: Synset('police.n.01'), Words: ['police']\n",
      "Synset: Synset('so.r.01'), Words: ['so']\n",
      "Synset: Synset('gather.v.01'), Words: ['gathered']\n",
      "Synset: Synset('signature.n.01'), Words: ['signatures']\n",
      "Synset: Synset('give.v.01'), Words: ['given']\n",
      "Synset: Synset('yet.r.01'), Words: ['yet']\n"
     ]
    }
   ],
   "source": [
    "# Print Lexical Chains as a Dictionary\n",
    "for synset, words in lexical_chains_dict.items():\n",
    "    print(f\"Synset: {synset}, Words: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "951046cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: Synset('london.n.01'), Length: 4, Distinct Occurrences: 1, Homogeneity Index: 0.75, Score: 3.0\n",
      "Synset: Synset('bomb.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('survivor.n.01'), Length: 7, Distinct Occurrences: 3, Homogeneity Index: 0.5714285714285714, Score: 4.0\n",
      "Synset: Synset('establish.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('political_campaign.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('public.a.01'), Length: 5, Distinct Occurrences: 1, Homogeneity Index: 0.8, Score: 4.0\n",
      "Synset: Synset('inquiry.n.01'), Length: 8, Distinct Occurrences: 2, Homogeneity Index: 0.75, Score: 6.0\n",
      "Synset: Synset('sunday.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('december.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('bombing.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('have.v.01'), Length: 14, Distinct Occurrences: 2, Homogeneity Index: 0.8571428571428571, Score: 12.0\n",
      "Synset: Synset('urge.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('british.a.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('populace.n.01'), Length: 3, Distinct Occurrences: 2, Homogeneity Index: 0.3333333333333333, Score: 1.0\n",
      "Synset: Synset('write.v.01'), Length: 3, Distinct Occurrences: 3, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('mononuclear_phagocyte_system.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('put.v.01'), Length: 4, Distinct Occurrences: 2, Homogeneity Index: 0.5, Score: 2.0\n",
      "Synset: Synset('up.r.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('on-line.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('request.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('name.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('independent.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('attack.n.01'), Length: 4, Distinct Occurrences: 2, Homogeneity Index: 0.5, Score: 2.0\n",
      "Synset: Synset('people.n.01'), Length: 2, Distinct Occurrences: 2, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('be.v.01'), Length: 47, Distinct Occurrences: 7, Homogeneity Index: 0.851063829787234, Score: 40.0\n",
      "Synset: Synset('kill.v.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('hundred.n.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('more.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('injured.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('july.n.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('suicide.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('bomber.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('blow.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('separate.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('underground.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('train.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('bus.n.01'), Length: 2, Distinct Occurrences: 2, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('earlier.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('week.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('government.n.01'), Length: 5, Distinct Occurrences: 1, Homogeneity Index: 0.8, Score: 4.0\n",
      "Synset: Synset('reject.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('call.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('argue.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('probe.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('excessively.r.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('expensive.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('take.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('long.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('distraction.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('attempt.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('battle.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('terrorism.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('alternatively.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('offer.v.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('together.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('narrative.s.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('event.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('fully.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('comprehensive.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('teach.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('valuable.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('lesson.n.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('help.v.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('reduce.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('likelihood.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('future.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('better.v.02'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('response.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('capability.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('emergency.n.01'), Length: 3, Distinct Occurrences: 2, Homogeneity Index: 0.3333333333333333, Score: 1.0\n",
      "Synset: Synset('services.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('such.s.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('rachel.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('north.n.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('pseudonym.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('active.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('organize.v.04'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('support.n.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('group.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('victim.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('anger.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('alternate.s.02'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('proposal.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('get_down.v.07'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('come.v.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('footing.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('aftermath.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('multiple_sclerosis.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('state.v.01'), Length: 6, Distinct Occurrences: 4, Homogeneity Index: 0.3333333333333333, Score: 2.0\n",
      "Synset: Synset('even.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('make.v.01'), Length: 9, Distinct Occurrences: 6, Homogeneity Index: 0.3333333333333333, Score: 3.0\n",
      "Synset: Synset('wish.v.02'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('question.n.01'), Length: 6, Distinct Occurrences: 2, Homogeneity Index: 0.6666666666666666, Score: 4.0\n",
      "Synset: Synset('answer.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('think.v.01'), Length: 2, Distinct Occurrences: 2, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('know.v.01'), Length: 4, Distinct Occurrences: 1, Homogeneity Index: 0.75, Score: 3.0\n",
      "Synset: Synset('already.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('mister.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('blair.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('not.r.01'), Length: 5, Distinct Occurrences: 1, Homogeneity Index: 0.8, Score: 4.0\n",
      "Synset: Synset('pay.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('cost.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('answer.v.01'), Length: 3, Distinct Occurrences: 2, Homogeneity Index: 0.3333333333333333, Score: 1.0\n",
      "Synset: Synset('writhe.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('then.r.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('bad.a.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('run.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('hazard.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('street.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('day.n.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('dare.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('assume.v.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('happen.v.01'), Length: 4, Distinct Occurrences: 1, Homogeneity Index: 0.75, Score: 3.0\n",
      "Synset: Synset('child.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('pacify.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('narrative.n.01'), Length: 2, Distinct Occurrences: 2, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('desire.v.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('besides.r.02'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('quote.v.01'), Length: 2, Distinct Occurrences: 2, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('number.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('other.a.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('constantly.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('remind.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('worst.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('peace.n.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('time.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('bombard.v.02'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('ever.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('see.v.01'), Length: 2, Distinct Occurrences: 2, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('die.v.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('family.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('lose.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('person.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('love.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('still.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('suffer.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('monetary_value.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('apparently.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('nothing.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('certain.a.02'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('learn.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('case.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('god.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('again.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('topographic_point.n.01'), Length: 3, Distinct Occurrences: 1, Homogeneity Index: 0.6666666666666666, Score: 2.0\n",
      "Synset: Synset('antic.s.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('occupation.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('spectacularly.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('anonymous.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('yorkshire.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('lass.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('web_site.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('watch.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('al-qaeda.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('video.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('declare.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('jihad.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('united_kingdom.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('haunt.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('acquaintance.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('voice.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('accent.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('dialect.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('man.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('enroll.v.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('train.v.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('far.r.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('away.r.01'), Length: 3, Distinct Occurrences: 2, Homogeneity Index: 0.3333333333333333, Score: 1.0\n",
      "Synset: Synset('state.n.04'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('barely.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('hear.v.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('populate.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('minutes.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('mother.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('home.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('bear.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('raise.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('words.n.01'), Length: 4, Distinct Occurrences: 1, Homogeneity Index: 0.75, Score: 3.0\n",
      "Synset: Synset('talk.v.02'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('similar.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('many.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('times.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('disillusioned.s.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('young.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('work_force.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('analyze.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('angstrom.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('degree.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('catch.v.14'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('work.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('worker.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('local.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('college.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('student.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('educate.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('follow.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('action.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('opinion.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('detriment.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('necessitate.v.01'), Length: 2, Distinct Occurrences: 2, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('ask.v.01'), Length: 2, Distinct Occurrences: 2, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('prevention.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('mind.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('look.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('justice.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('incorrect.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('manner.n.01'), Length: 3, Distinct Occurrences: 2, Homogeneity Index: 0.3333333333333333, Score: 1.0\n",
      "Synset: Synset('right.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('however.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('kind.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('resolution.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('travel.v.01'), Length: 4, Distinct Occurrences: 2, Homogeneity Index: 0.5, Score: 2.0\n",
      "Synset: Synset('commuter.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('summer.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('relative.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('dead.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('very.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('critical.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('saba.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('daughter.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('line.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('explosion.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('campaign.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('full.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('satisfy.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('son.n.01'), Length: 2, Distinct Occurrences: 1, Homogeneity Index: 0.5, Score: 1.0\n",
      "Synset: Synset('antony.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('truly.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('hide.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('shy.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('lone.s.03'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('real.a.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('get.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('things.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('discourse.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('better.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('fix.v.12'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('now.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('never.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('back.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('cipher.n.04'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('waste.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('police.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('so.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('gather.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('signature.n.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('give.v.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n",
      "Synset: Synset('yet.r.01'), Length: 1, Distinct Occurrences: 1, Homogeneity Index: 0.0, Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#LEXICAL CHAIN SCORING\n",
    "scores_list = []\n",
    "for synset, words in lexical_chains_dict.items():\n",
    "    length = len(words)\n",
    "    distinct_occurrences = len(set(words))\n",
    "    \n",
    "    if length > 0:\n",
    "        homogeneity_index = (length - distinct_occurrences) / length\n",
    "    else:\n",
    "        homogeneity_index = 0\n",
    "    \n",
    "    score = length * homogeneity_index\n",
    "    # Append the score to the list\n",
    "    scores_list.append(score)\n",
    "    print(f\"Synset: {synset}, Length: {length}, Distinct Occurrences: {distinct_occurrences}, Homogeneity Index: {homogeneity_index}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2a714b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Chain Scores\n",
      "mean= 0.6814516129032258\n",
      "standard deviation= 2.766325935811354\n"
     ]
    }
   ],
   "source": [
    "# Convert the list of scores to a numpy array\n",
    "scores_array = np.array(scores_list)\n",
    "print('Lexical Chain Scores')\n",
    "scores_mean=np.mean(scores_array)\n",
    "print('mean=' ,scores_mean)\n",
    "\n",
    "scores_std_dev=np.std(scores_array)\n",
    "print('standard deviation=' , scores_std_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62383103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Strong Lexical Chain \n",
    "#Threshold\n",
    "threshold = scores_mean + 2 * scores_std_dev\n",
    "\n",
    "selected_chains_dict = {}\n",
    "\n",
    "# Filtering lexical chains \n",
    "for synset, words in lexical_chains_dict.items():\n",
    "    length = len(words)\n",
    "    distinct_occurrences = len(set(words))\n",
    "    \n",
    "    if length > 0:\n",
    "        homogeneity_index = (length - distinct_occurrences) / length\n",
    "    else:\n",
    "        homogeneity_index = 0\n",
    "    \n",
    "    score = length * homogeneity_index\n",
    "\n",
    "    if score > threshold:\n",
    "        selected_chains_dict[synset] = {\n",
    "            'sentence': synset.definition(),  \n",
    "            'score': score\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6cb8aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Lexical Chains:\n",
      "Synset: Synset('have.v.01'), Score: 12.0\n",
      "Synset: Synset('be.v.01'), Score: 40.0\n"
     ]
    }
   ],
   "source": [
    "# Print the selected lexical chains\n",
    "print(\"Selected Lexical Chains:\")\n",
    "for synset, info in selected_chains_dict.items():\n",
    "    print(f\"Synset: {synset}, Score: {info['score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "875fa160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract words from selected lexical chains\n",
    "selected_lexical_chain = set()\n",
    "for info in selected_chains_dict.values():\n",
    "    definition_words = word_tokenize(info['sentence'])\n",
    "    selected_lexical_chain.update(definition_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b69e2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: London bomb survivors launch campaign for public inquiry\n",
      "\n",
      "Sunday, December 18, 2005\n",
      "\n",
      "Survivors of the London Bombings have urged the British public to write to their MPs, and set up an online petition calling for an independent Public Inquiry into the attacks., Noun Count: 16, Sentence Length: 46, Score: 0.34782608695652173\n",
      "Sentence: \n",
      "\n",
      "52 people were killed and hundreds more injured on July 7th 2005 when four suicide bombers blew themselves up on three separate London Underground trains and a public bus., Noun Count: 9, Sentence Length: 30, Score: 0.3\n",
      "Sentence: \n",
      "\n",
      "Earlier this week the British government rejected calls for a Public Inquiry, arguing that such an investigation would be too expensive, take too long, and be a distraction from their efforts to combat terrorism., Noun Count: 9, Sentence Length: 38, Score: 0.23684210526315788\n",
      "Sentence: Instead, the government has offered to put together a \"narrative of events\"., Noun Count: 2, Sentence Length: 16, Score: 0.125\n",
      "Sentence: \n",
      "\n",
      "But survivors of the attack argue that a fully comprehensive investigation could teach valuable lessons which may help reduce the likelihood of future attacks, and improve the response capabilities of the emergency services., Noun Count: 11, Sentence Length: 35, Score: 0.3142857142857143\n",
      "Sentence: \n",
      "\n",
      "Some survivors, such as Rachel North (a pseudonym), who has been active in organising a support group for her fellow victims, have been angered by the government's alternative proposal of a \"narrative\"., Noun Count: 9, Sentence Length: 41, Score: 0.21951219512195122\n",
      "Sentence: Writing on the weblog she started to help her, and others, come to terms with the aftermath of July 7th, Ms North says:\n",
      "\n",
      "\"Even if you don't like the questions, don't like the answers, think you know the answers already, Mr Blair, it is us, not you, who are paying the cost for this... If the cost of answering questions makes you squirm, then too bad... We run the risks on the trains, the buses, the streets each day... How dare you presume you know our questions and how dare you presume that they can be answered by a 'narrative of what happened', as if we are children to be placated with a story., Noun Count: 25, Sentence Length: 136, Score: 0.18382352941176472\n",
      "Sentence: I know what happened, I want to know why.\", Noun Count: 0, Sentence Length: 12, Score: 0.0\n",
      "Sentence: \n",
      "\n",
      "Ms North also quotes a number of other survivors:\n",
      "\n",
      "\"We are constantly reminded that this is the worst peace time bombing London has ever seen, for something that bad there should be an inquiry., Noun Count: 9, Sentence Length: 38, Score: 0.23684210526315788\n",
      "Sentence: People died, families lost someone they loved and hundreds are still suffering., Noun Count: 4, Sentence Length: 14, Score: 0.2857142857142857\n",
      "Sentence: You can't put a price on that but apparently the government can.\" - \", Noun Count: 2, Sentence Length: 17, Score: 0.11764705882352941\n",
      "Sentence: Fiona\"\n",
      "\n",
      "\"If nothing else, an enquiry would make sure some of these lessons were learnt in case, God forbid, anything like this happened again., Noun Count: 8, Sentence Length: 30, Score: 0.26666666666666666\n",
      "Sentence: I thought there were plansin place for emergencies such as this., Noun Count: 2, Sentence Length: 12, Score: 0\n",
      "Sentence: Whilst the emergency services did a fantastic job on the day, I have been stunningly underwhelmed by the support offered to victims since.\" - \", Noun Count: 6, Sentence Length: 28, Score: 0.21428571428571427\n",
      "Sentence: Pauline\"\n",
      "\n",
      "An anonymous survivor, writing on the \"Yorkshire lass\" website, says:\n",
      "\n",
      "\"'When I watched the Al-Qaeda video declaring Jihad against the UK I was haunted by the familiarity of the voice, it was my voice, my accent, my dialect., Noun Count: 14, Sentence Length: 50, Score: 0.28\n",
      "Sentence: This is not a man who was recruited and trained in some far off country that I have barely heard of, this was a man who was recruited and trained while he lived 20 minutes from my mother's home where I was born and raised., Noun Count: 6, Sentence Length: 48, Score: 0.125\n",
      "Sentence: The words he spoke of are words similar to what I have heard many times from disillusioned young men that I studied for my A Levels with., Noun Count: 6, Sentence Length: 28, Score: 0.21428571428571427\n",
      "Sentence: They are the words of hatred I overheard when I worked as a support worker at my local college., Noun Count: 4, Sentence Length: 20, Score: 0.2\n",
      "Sentence: They were words of students who were educated... when someone follows through with the actions of those opinions to the detriment of others, questions need to be asked why preventions were not put in place and this needs to be done by public inquiry for peace of mind., Noun Count: 13, Sentence Length: 51, Score: 0.2549019607843137\n",
      "Sentence: I have been told that I am looking for justice in the wrong place and in some way that is right., Noun Count: 3, Sentence Length: 22, Score: 0.13636363636363635\n",
      "Sentence: However, I want some sort of justice, some manner of peace of mind, some questions answered and resolutions made., Noun Count: 7, Sentence Length: 23, Score: 0.30434782608695654\n",
      "Sentence: I don't want others to have to go through what myself and hundreds of other commuters did on that Summer's day.'\", Noun Count: 5, Sentence Length: 26, Score: 0.19230769230769232\n",
      "Sentence: \n",
      "\n",
      "Relatives of the dead have also been very critical., Noun Count: 1, Sentence Length: 10, Score: 0.1\n",
      "Sentence: Quoted on the BBC's website, Saba Mozakka, the daughter of Behnaz Mozakka,who died in the Piccadilly Line explosion, said:\n",
      "\n",
      "\"The families will be campaigning for there to be a full public inquiry... A narrative of events will not satisfy anybody., Noun Count: 16, Sentence Length: 50, Score: 0.32\n",
      "Sentence: This is not something we will go away on.\", Noun Count: 1, Sentence Length: 11, Score: 0\n",
      "Sentence: \n",
      "\n",
      "Marie Fatayi-Williams, whose son Anthony was killed in the attack, told the BBC: \"I ask myself - if there is really nothing to hide then why shy away from a public inquiry?, Noun Count: 8, Sentence Length: 37, Score: 0.21621621621621623\n",
      "Sentence: It is the only real way that we can truly get things discussed and see for ourselves what happened and what lessons can be learnt and whether we are better prepared now than on 7 July... I have a son who was killed and is never going to come back., Noun Count: 5, Sentence Length: 52, Score: 0.09615384615384616\n",
      "Sentence: Nobody is going to tell me that [an inquiry] is a waste of police time.\", Noun Count: 6, Sentence Length: 19, Score: 0.3157894736842105\n",
      "Sentence: \n",
      "\n",
      "The survivors' petition has so far gathered over 100 signatures., Noun Count: 3, Sentence Length: 12, Score: 0\n",
      "Sentence: The British government has given no response as yet., Noun Count: 2, Sentence Length: 10, Score: 0\n"
     ]
    }
   ],
   "source": [
    "#Sentence Scoring\n",
    "sentence_scores_list=[]\n",
    "# Iterate over sentences and calculate scores based on the presence of words in selected lexical chains\n",
    "for sent in sents_list:\n",
    "    tokens = word_tokenize(sent)\n",
    "    noun_count = sum(1 for word, pos in pos_tag(tokens) if pos.startswith('N'))\n",
    "    sentence_length = len(tokens)\n",
    "\n",
    "    # Check if there is any word from the selected lexical chains in the sentence\n",
    "    if any(word in selected_lexical_chain for word in tokens):\n",
    "        # Calculate the sentence score based on noun_count and sentence_length\n",
    "        sentence_score = noun_count / sentence_length\n",
    "    else:\n",
    "        # If no word from the selected lexical chains is found, set the sentence score to 0\n",
    "        sentence_score = 0\n",
    "\n",
    "    sentence_scores_list.append(sentence_score)\n",
    "    print(f\"Sentence: {sent}, Noun Count: {noun_count}, Sentence Length: {sentence_length}, Score: {sentence_score}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77296ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34782609 0.3        0.23684211 0.125      0.31428571 0.2195122\n",
      " 0.18382353 0.         0.23684211 0.28571429 0.11764706 0.26666667\n",
      " 0.         0.21428571 0.28       0.125      0.21428571 0.2\n",
      " 0.25490196 0.13636364 0.30434783 0.19230769 0.1        0.32\n",
      " 0.         0.21621622 0.09615385 0.31578947 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "sentence_scores = np.array(sentence_scores_list)\n",
    "print(sentence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a34c5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18679372758916832\n"
     ]
    }
   ],
   "source": [
    "mean_score = np.mean(sentence_scores)\n",
    "print(mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "065c88c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proper Noun: London, Frequency: 2\n",
      "Proper Noun: Sunday, Frequency: 1\n",
      "Proper Noun: December, Frequency: 1\n",
      "Proper Noun: MPs, Frequency: 1\n",
      "Proper Noun: Public, Frequency: 1\n",
      "Proper Noun: Inquiry, Frequency: 1\n",
      "Proper Noun: July, Frequency: 1\n",
      "Proper Noun: Underground, Frequency: 1\n",
      "Proper Noun: Rachel, Frequency: 1\n",
      "Proper Noun: North, Frequency: 1\n",
      "Proper Noun: Ms, Frequency: 1\n",
      "Proper Noun: Mr, Frequency: 1\n",
      "Proper Noun: Blair, Frequency: 1\n",
      "Proper Noun: God, Frequency: 1\n",
      "Proper Noun: Yorkshire, Frequency: 1\n",
      "Proper Noun: Al-Qaeda, Frequency: 1\n",
      "Proper Noun: Jihad, Frequency: 1\n",
      "Proper Noun: UK, Frequency: 1\n",
      "Proper Noun: Levels, Frequency: 1\n",
      "Proper Noun: Summer, Frequency: 1\n",
      "Proper Noun: BBC, Frequency: 1\n",
      "Proper Noun: Saba, Frequency: 1\n",
      "Proper Noun: Mozakka, Frequency: 2\n",
      "Proper Noun: Behnaz, Frequency: 1\n",
      "Proper Noun: Piccadilly, Frequency: 1\n",
      "Proper Noun: Line, Frequency: 1\n",
      "Proper Noun: A, Frequency: 1\n",
      "Proper Noun: Marie, Frequency: 1\n",
      "Proper Noun: Fatayi-Williams, Frequency: 1\n",
      "Proper Noun: Anthony, Frequency: 1\n"
     ]
    }
   ],
   "source": [
    "#PROPER NOUN SCORING\n",
    "\n",
    "# Proper Noun Scoring\n",
    "proper_noun_scores = {}\n",
    "\n",
    "for sent in sents_list:\n",
    "    tokens = word_tokenize(sent)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    for token, pos in pos_tags:\n",
    "        if pos == 'NNP' and token not in proper_noun_scores:\n",
    "            proper_noun_scores[token] = pos_tags.count((token, pos))\n",
    "\n",
    "# Print Proper Noun Scores\n",
    "for proper_noun, frequency in proper_noun_scores.items():\n",
    "    print(f\"Proper Noun: {proper_noun}, Frequency: {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f5ded2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "\n",
    "#summary.append(sents_list[0])  # Add the entire sentence as a single element to the list\n",
    "#print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c69fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary using Sentence Scoring\n",
    "#The zip function combines elements from sents_list and sentence_scores_list into pairs of (sent, score).\n",
    "for sent, score in zip(sents_list, sentence_scores_list):\n",
    "    if score > mean_score:\n",
    "        summary.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3918413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "London bomb survivors launch campaign for public inquiry\n",
      "\n",
      "Sunday, December 18, 2005\n",
      "\n",
      "Survivors of the London Bombings have urged the British public to write to their MPs, and set up an online petition calling for an independent Public Inquiry into the attacks.\n",
      "\n",
      "\n",
      "52 people were killed and hundreds more injured on July 7th 2005 when four suicide bombers blew themselves up on three separate London Underground trains and a public bus.\n",
      "\n",
      "\n",
      "Earlier this week the British government rejected calls for a Public Inquiry, arguing that such an investigation would be too expensive, take too long, and be a distraction from their efforts to combat terrorism.\n",
      "\n",
      "\n",
      "But survivors of the attack argue that a fully comprehensive investigation could teach valuable lessons which may help reduce the likelihood of future attacks, and improve the response capabilities of the emergency services.\n",
      "\n",
      "\n",
      "Some survivors, such as Rachel North (a pseudonym), who has been active in organising a support group for her fellow victims, have been angered by the government's alternative proposal of a \"narrative\".\n",
      "\n",
      "\n",
      "Ms North also quotes a number of other survivors:\n",
      "\n",
      "\"We are constantly reminded that this is the worst peace time bombing London has ever seen, for something that bad there should be an inquiry.\n",
      "People died, families lost someone they loved and hundreds are still suffering.\n",
      "Fiona\"\n",
      "\n",
      "\"If nothing else, an enquiry would make sure some of these lessons were learnt in case, God forbid, anything like this happened again.\n",
      "Whilst the emergency services did a fantastic job on the day, I have been stunningly underwhelmed by the support offered to victims since.\" - \"\n",
      "Pauline\"\n",
      "\n",
      "An anonymous survivor, writing on the \"Yorkshire lass\" website, says:\n",
      "\n",
      "\"'When I watched the Al-Qaeda video declaring Jihad against the UK I was haunted by the familiarity of the voice, it was my voice, my accent, my dialect.\n",
      "The words he spoke of are words similar to what I have heard many times from disillusioned young men that I studied for my A Levels with.\n",
      "They are the words of hatred I overheard when I worked as a support worker at my local college.\n",
      "They were words of students who were educated... when someone follows through with the actions of those opinions to the detriment of others, questions need to be asked why preventions were not put in place and this needs to be done by public inquiry for peace of mind.\n",
      "However, I want some sort of justice, some manner of peace of mind, some questions answered and resolutions made.\n",
      "I don't want others to have to go through what myself and hundreds of other commuters did on that Summer's day.'\"\n",
      "Quoted on the BBC's website, Saba Mozakka, the daughter of Behnaz Mozakka,who died in the Piccadilly Line explosion, said:\n",
      "\n",
      "\"The families will be campaigning for there to be a full public inquiry... A narrative of events will not satisfy anybody.\n",
      "\n",
      "\n",
      "Marie Fatayi-Williams, whose son Anthony was killed in the attack, told the BBC: \"I ask myself - if there is really nothing to hide then why shy away from a public inquiry?\n",
      "Nobody is going to tell me that [an inquiry] is a waste of police time.\"\n"
     ]
    }
   ],
   "source": [
    "# Print the summary\n",
    "print(\"Summary:\")\n",
    "for s in summary:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39a45ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary using Lexical Chains:\n",
      "London bomb survivors launch campaign for public inquiry\n",
      "\n",
      "Sunday, December 18, 2005\n",
      "\n",
      "Survivors of the London Bombings have urged the British public to write to their MPs, and set up an online petition calling for an independent Public Inquiry into the attacks.\n",
      "\n",
      "\n",
      "52 people were killed and hundreds more injured on July 7th 2005 when four suicide bombers blew themselves up on three separate London Underground trains and a public bus.\n",
      "\n",
      "\n",
      "Earlier this week the British government rejected calls for a Public Inquiry, arguing that such an investigation would be too expensive, take too long, and be a distraction from their efforts to combat terrorism.\n",
      "Instead, the government has offered to put together a \"narrative of events\".\n",
      "\n",
      "\n",
      "But survivors of the attack argue that a fully comprehensive investigation could teach valuable lessons which may help reduce the likelihood of future attacks, and improve the response capabilities of the emergency services.\n",
      "\n",
      "\n",
      "Some survivors, such as Rachel North (a pseudonym), who has been active in organising a support group for her fellow victims, have been angered by the government's alternative proposal of a \"narrative\".\n",
      "Writing on the weblog she started to help her, and others, come to terms with the aftermath of July 7th, Ms North says:\n",
      "\n",
      "\"Even if you don't like the questions, don't like the answers, think you know the answers already, Mr Blair, it is us, not you, who are paying the cost for this... If the cost of answering questions makes you squirm, then too bad... We run the risks on the trains, the buses, the streets each day... How dare you presume you know our questions and how dare you presume that they can be answered by a 'narrative of what happened', as if we are children to be placated with a story.\n",
      "I know what happened, I want to know why.\"\n",
      "\n",
      "\n",
      "Ms North also quotes a number of other survivors:\n",
      "\n",
      "\"We are constantly reminded that this is the worst peace time bombing London has ever seen, for something that bad there should be an inquiry.\n",
      "People died, families lost someone they loved and hundreds are still suffering.\n",
      "You can't put a price on that but apparently the government can.\" - \"\n",
      "Fiona\"\n",
      "\n",
      "\"If nothing else, an enquiry would make sure some of these lessons were learnt in case, God forbid, anything like this happened again.\n",
      "Whilst the emergency services did a fantastic job on the day, I have been stunningly underwhelmed by the support offered to victims since.\" - \"\n",
      "Pauline\"\n",
      "\n",
      "An anonymous survivor, writing on the \"Yorkshire lass\" website, says:\n",
      "\n",
      "\"'When I watched the Al-Qaeda video declaring Jihad against the UK I was haunted by the familiarity of the voice, it was my voice, my accent, my dialect.\n",
      "This is not a man who was recruited and trained in some far off country that I have barely heard of, this was a man who was recruited and trained while he lived 20 minutes from my mother's home where I was born and raised.\n",
      "The words he spoke of are words similar to what I have heard many times from disillusioned young men that I studied for my A Levels with.\n",
      "They are the words of hatred I overheard when I worked as a support worker at my local college.\n",
      "They were words of students who were educated... when someone follows through with the actions of those opinions to the detriment of others, questions need to be asked why preventions were not put in place and this needs to be done by public inquiry for peace of mind.\n",
      "I have been told that I am looking for justice in the wrong place and in some way that is right.\n",
      "However, I want some sort of justice, some manner of peace of mind, some questions answered and resolutions made.\n",
      "I don't want others to have to go through what myself and hundreds of other commuters did on that Summer's day.'\"\n",
      "\n",
      "\n",
      "Relatives of the dead have also been very critical.\n",
      "Quoted on the BBC's website, Saba Mozakka, the daughter of Behnaz Mozakka,who died in the Piccadilly Line explosion, said:\n",
      "\n",
      "\"The families will be campaigning for there to be a full public inquiry... A narrative of events will not satisfy anybody.\n",
      "\n",
      "\n",
      "Marie Fatayi-Williams, whose son Anthony was killed in the attack, told the BBC: \"I ask myself - if there is really nothing to hide then why shy away from a public inquiry?\n",
      "It is the only real way that we can truly get things discussed and see for ourselves what happened and what lessons can be learnt and whether we are better prepared now than on 7 July... I have a son who was killed and is never going to come back.\n",
      "Nobody is going to tell me that [an inquiry] is a waste of police time.\"\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the summary sentences\n",
    "summary_sentences = []\n",
    "\n",
    "# Iterate over sentences and check if any word from the selected lexical chains is present\n",
    "for sent in sents_list:\n",
    "    tokens = word_tokenize(sent)\n",
    "\n",
    "    # Check if there is any word from the selected lexical chains in the sentence\n",
    "    if any(word in selected_lexical_chain for word in tokens):\n",
    "        summary_sentences.append(sent)\n",
    "\n",
    "# Print the summary sentences\n",
    "print(\"Summary using Lexical Chains:\")\n",
    "for s in summary_sentences:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff93fb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "Selected Proper Nouns:\n",
      "[]\n",
      "Summary using Proper Noun Scoring:\n"
     ]
    }
   ],
   "source": [
    "#Using Proper Noun Scoring\n",
    "# Define the threshold for proper noun scoring\n",
    "proper_noun_threshold = 1/3 * len(sents_list)\n",
    "print(proper_noun_threshold)\n",
    "# Initialize a list to store proper nouns that satisfy the criteria\n",
    "selected_proper_nouns = []\n",
    "\n",
    "# Iterate over proper nouns and check if the frequency is above the threshold\n",
    "for proper_noun, frequency in proper_noun_scores.items():\n",
    "    if frequency > proper_noun_threshold:\n",
    "        selected_proper_nouns.append(proper_noun)\n",
    "\n",
    "# Print the selected proper nouns\n",
    "print(\"Selected Proper Nouns:\")\n",
    "print(selected_proper_nouns)\n",
    "\n",
    "# Initialize a list to store sentences for the summary\n",
    "proper_noun_summary = []\n",
    "\n",
    "# Iterate over sentences and check if they contain selected proper nouns\n",
    "for sent in sents_list:\n",
    "    tokens = word_tokenize(sent)\n",
    "\n",
    "    # Check if the sentence contains any selected proper noun\n",
    "    if any(proper_noun in tokens for proper_noun in selected_proper_nouns):\n",
    "        proper_noun_summary.append(sent)\n",
    "\n",
    "# Print the proper noun summary\n",
    "print(\"Summary using Proper Noun Scoring:\")\n",
    "for s in proper_noun_summary:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54557e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Summary:\n",
      "London bomb survivors launch campaign for public inquiry\n",
      "\n",
      "Sunday, December 18, 2005\n",
      "\n",
      "Survivors of the London Bombings have urged the British public to write to their MPs, and set up an online petition calling for an independent Public Inquiry into the attacks.\n",
      "\n",
      "\n",
      "52 people were killed and hundreds more injured on July 7th 2005 when four suicide bombers blew themselves up on three separate London Underground trains and a public bus.\n",
      "\n",
      "\n",
      "Earlier this week the British government rejected calls for a Public Inquiry, arguing that such an investigation would be too expensive, take too long, and be a distraction from their efforts to combat terrorism.\n",
      "Instead, the government has offered to put together a \"narrative of events\".\n",
      "\n",
      "\n",
      "But survivors of the attack argue that a fully comprehensive investigation could teach valuable lessons which may help reduce the likelihood of future attacks, and improve the response capabilities of the emergency services.\n",
      "\n",
      "\n",
      "Some survivors, such as Rachel North (a pseudonym), who has been active in organising a support group for her fellow victims, have been angered by the government's alternative proposal of a \"narrative\".\n",
      "Writing on the weblog she started to help her, and others, come to terms with the aftermath of July 7th, Ms North says:\n",
      "\n",
      "\"Even if you don't like the questions, don't like the answers, think you know the answers already, Mr Blair, it is us, not you, who are paying the cost for this... If the cost of answering questions makes you squirm, then too bad... We run the risks on the trains, the buses, the streets each day... How dare you presume you know our questions and how dare you presume that they can be answered by a 'narrative of what happened', as if we are children to be placated with a story.\n",
      "I know what happened, I want to know why.\"\n",
      "\n",
      "\n",
      "Ms North also quotes a number of other survivors:\n",
      "\n",
      "\"We are constantly reminded that this is the worst peace time bombing London has ever seen, for something that bad there should be an inquiry.\n",
      "People died, families lost someone they loved and hundreds are still suffering.\n",
      "You can't put a price on that but apparently the government can.\" - \"\n",
      "Fiona\"\n",
      "\n",
      "\"If nothing else, an enquiry would make sure some of these lessons were learnt in case, God forbid, anything like this happened again.\n",
      "Whilst the emergency services did a fantastic job on the day, I have been stunningly underwhelmed by the support offered to victims since.\" - \"\n",
      "Pauline\"\n",
      "\n",
      "An anonymous survivor, writing on the \"Yorkshire lass\" website, says:\n",
      "\n",
      "\"'When I watched the Al-Qaeda video declaring Jihad against the UK I was haunted by the familiarity of the voice, it was my voice, my accent, my dialect.\n",
      "This is not a man who was recruited and trained in some far off country that I have barely heard of, this was a man who was recruited and trained while he lived 20 minutes from my mother's home where I was born and raised.\n",
      "The words he spoke of are words similar to what I have heard many times from disillusioned young men that I studied for my A Levels with.\n",
      "They are the words of hatred I overheard when I worked as a support worker at my local college.\n",
      "They were words of students who were educated... when someone follows through with the actions of those opinions to the detriment of others, questions need to be asked why preventions were not put in place and this needs to be done by public inquiry for peace of mind.\n",
      "I have been told that I am looking for justice in the wrong place and in some way that is right.\n",
      "However, I want some sort of justice, some manner of peace of mind, some questions answered and resolutions made.\n",
      "I don't want others to have to go through what myself and hundreds of other commuters did on that Summer's day.'\"\n",
      "\n",
      "\n",
      "Relatives of the dead have also been very critical.\n",
      "Quoted on the BBC's website, Saba Mozakka, the daughter of Behnaz Mozakka,who died in the Piccadilly Line explosion, said:\n",
      "\n",
      "\"The families will be campaigning for there to be a full public inquiry... A narrative of events will not satisfy anybody.\n",
      "\n",
      "\n",
      "Marie Fatayi-Williams, whose son Anthony was killed in the attack, told the BBC: \"I ask myself - if there is really nothing to hide then why shy away from a public inquiry?\n",
      "It is the only real way that we can truly get things discussed and see for ourselves what happened and what lessons can be learnt and whether we are better prepared now than on 7 July... I have a son who was killed and is never going to come back.\n",
      "Nobody is going to tell me that [an inquiry] is a waste of police time.\"\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Combine summaries from Lexical Chains, Sentence Scoring, and Proper Noun Scoring\n",
    "combined_summaries = summary_sentences + summary + proper_noun_summary\n",
    "\n",
    "# Use an OrderedDict to preserve order and remove duplicates\n",
    "unique_summary = OrderedDict.fromkeys(combined_summaries)\n",
    "\n",
    "# Print the final summary without duplicates and in the correct order\n",
    "print(\"Final Summary:\")\n",
    "for s in unique_summary:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5aa8e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London bomb survivors launch campaign for public inquiry\n",
      "\n",
      "Sunday, December 18, 2005\n",
      "\n",
      "Survivors of the London Bombings have urged the British public to write to their MPs, and set up an online petition calling for an independent Public Inquiry into the attacks. \n",
      "\n",
      "52 people were killed and hundreds more injured on July 7th 2005 when four suicide bombers blew themselves up on three separate London Underground trains and a public bus. \n",
      "\n",
      "Earlier this week the British government rejected calls for a Public Inquiry, arguing that such an investigation would be too expensive, take too long, and be a distraction from their efforts to combat terrorism. Instead, the government has offered to put together a \"narrative of events\". \n",
      "\n",
      "But survivors of the attack argue that a fully comprehensive investigation could teach valuable lessons which may help reduce the likelihood of future attacks, and improve the response capabilities of the emergency services. \n",
      "\n",
      "Some survivors, such as Rachel North (a pseudonym), who has been active in organising a support group for her fellow victims, have been angered by the government's alternative proposal of a \"narrative\". Writing on the weblog she started to help her, and others, come to terms with the aftermath of July 7th, Ms North says:\n",
      "\n",
      "\"Even if you don't like the questions, don't like the answers, think you know the answers already, Mr Blair, it is us, not you, who are paying the cost for this... If the cost of answering questions makes you squirm, then too bad... We run the risks on the trains, the buses, the streets each day... How dare you presume you know our questions and how dare you presume that they can be answered by a 'narrative of what happened', as if we are children to be placated with a story. I know what happened, I want to know why.\" \n",
      "\n",
      "Ms North also quotes a number of other survivors:\n",
      "\n",
      "\"We are constantly reminded that this is the worst peace time bombing London has ever seen, for something that bad there should be an inquiry. People died, families lost someone they loved and hundreds are still suffering. You can't put a price on that but apparently the government can.\" - \" Fiona\"\n",
      "\n",
      "\"If nothing else, an enquiry would make sure some of these lessons were learnt in case, God forbid, anything like this happened again. Whilst the emergency services did a fantastic job on the day, I have been stunningly underwhelmed by the support offered to victims since.\" - \" Pauline\"\n",
      "\n",
      "An anonymous survivor, writing on the \"Yorkshire lass\" website, says:\n",
      "\n",
      "\"'When I watched the Al-Qaeda video declaring Jihad against the UK I was haunted by the familiarity of the voice, it was my voice, my accent, my dialect. This is not a man who was recruited and trained in some far off country that I have barely heard of, this was a man who was recruited and trained while he lived 20 minutes from my mother's home where I was born and raised. The words he spoke of are words similar to what I have heard many times from disillusioned young men that I studied for my A Levels with. They are the words of hatred I overheard when I worked as a support worker at my local college. They were words of students who were educated... when someone follows through with the actions of those opinions to the detriment of others, questions need to be asked why preventions were not put in place and this needs to be done by public inquiry for peace of mind. I have been told that I am looking for justice in the wrong place and in some way that is right. However, I want some sort of justice, some manner of peace of mind, some questions answered and resolutions made. I don't want others to have to go through what myself and hundreds of other commuters did on that Summer's day.'\" \n",
      "\n",
      "Relatives of the dead have also been very critical. Quoted on the BBC's website, Saba Mozakka, the daughter of Behnaz Mozakka,who died in the Piccadilly Line explosion, said:\n",
      "\n",
      "\"The families will be campaigning for there to be a full public inquiry... A narrative of events will not satisfy anybody. \n",
      "\n",
      "Marie Fatayi-Williams, whose son Anthony was killed in the attack, told the BBC: \"I ask myself - if there is really nothing to hide then why shy away from a public inquiry? It is the only real way that we can truly get things discussed and see for ourselves what happened and what lessons can be learnt and whether we are better prepared now than on 7 July... I have a son who was killed and is never going to come back. Nobody is going to tell me that [an inquiry] is a waste of police time.\"\n"
     ]
    }
   ],
   "source": [
    "#Unique Summary to a string\n",
    "# Convert the unique_summary to a single string\n",
    "final_summary_string = ' '.join(unique_summary.keys())\n",
    "print(final_summary_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "795a6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6840c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(text, language='en', output_file='speech.mp3'):\n",
    "    # Translate the text to the specified language\n",
    "    translator = Translator()\n",
    "    translated_text = translator.translate(text, dest=language).text\n",
    "\n",
    "    # Initialize gTTS with the translated text\n",
    "    speech = gTTS(translated_text, lang=language)\n",
    "\n",
    "    # Save the translated audio file to a temporary file\n",
    "    speech.save(output_file)\n",
    "\n",
    "    # Play the audio file using the default program associated with .mp3 files\n",
    "    os.system('start ' + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0bf2cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#English\n",
    "\n",
    "text_to_speech(final_summary_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f923b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spanish\n",
    "text_to_speech(final_summary_string, language='es', output_file='speech_spanish.mp3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ec6caa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#French\n",
    "text_to_speech(final_summary_string, language='fr', output_file='speech_french.mp3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1729b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def save_model(model, filename): joblib.dump(model, filename)\n",
    "\n",
    "save_model(combined_summaries, 'combined_summaries.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05a576c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    return joblib.load(filename)\n",
    "\n",
    "combined_summaries = load_model('combined_summaries.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c288acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
